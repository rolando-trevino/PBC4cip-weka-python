{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gensim.models import LdaModel, CoherenceModel, LdaMulticore\n",
    "import gensim.corpora as corpora\n",
    "import time\n",
    "from gensim import models, corpora, similarities\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import entropy\n",
    "from scipy.spatial import distance\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Default value of display.max_rows is 10 i.e. at max 10 rows will be printed.\n",
    "# Set it None to display all rows in the dataframe\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Set it to None to display all columns in the dataframe\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset_nlp_clean.csv\")\n",
    "df['nlp_lemma'] = df['nlp_lemma'].replace(np.NaN, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_list = []\n",
    "tokens_list = []\n",
    "for index, row in df.iterrows():\n",
    "    texts = row['nlp_lemma']\n",
    "    # corpus = [id2word.doc2bow(text) for text in texts]\n",
    "    corpus_list.append(texts)\n",
    "    tokens_list.append(texts.split())\n",
    "df['tokens'] = tokens_list\n",
    "df['corpus'] = corpus_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Código del expediente Número del procedimiento Carácter del procedimiento  \\\n",
       "0                  50739     EO-823001999-N8-2011                   Nacional   \n",
       "1                  51475    EA-823001999-N10-2011                   Nacional   \n",
       "2                  61495    AO-811027990-N12-2011                        NaN   \n",
       "3                  65885     IO-815060972-N7-2011                   Nacional   \n",
       "4                  65850     IO-815060972-N8-2011                   Nacional   \n",
       "\n",
       "  Forma del procedimiento Artículo de excepción  \\\n",
       "0              Presencial                   NaN   \n",
       "1              Presencial                   NaN   \n",
       "2                     NaN           Art. 43 s/f   \n",
       "3                   Mixta           Art. 43 s/f   \n",
       "4                   Mixta           Art. 43 s/f   \n",
       "\n",
       "              REFERENCIA_EXPEDIENTE  \\\n",
       "0                               NaN   \n",
       "1                               NaN   \n",
       "2          DGOP/HABITAT/PROY/007-11   \n",
       "3  NR-OP-IR-PREP-15060-EMF-002/2011   \n",
       "4  NR-OP-IR-PREP-15060-EMF-001/2011   \n",
       "\n",
       "                                                        Título del expediente  \\\n",
       "0                     Mejoramiento de la iluminación de la Iglesia San Miguel   \n",
       "1  Adquisición de Uniformes para la dirección de Seguridad Pública y Transito   \n",
       "2                     PROYECTO EJECUTIVO JARDIN VECINAL COLONIA LAS AMERICAS    \n",
       "3                                      CONSTRUCCION DE DEPORTIVO BICENTENARIO   \n",
       "4                            ACONDICIONAMIENTO DE CENTRO CULTURAL Y DEPORTIVO   \n",
       "\n",
       "                                                     Plantilla del expediente  \\\n",
       "0   V20150817 30. Licitación Pública Nacional de Obra Pública (Norma Estatal)   \n",
       "1  V20150817 28. Licitación Pública Nacional de Adquisiciones (Norma Estatal)   \n",
       "2                                             06. Adjudicación Directa LOPSRM   \n",
       "3                V20151220 19. Invitación a cuando menos tres Nacional LOPSRM   \n",
       "4                V20151220 19. Invitación a cuando menos tres Nacional LOPSRM   \n",
       "\n",
       "                                                                   Descripción del Anuncio  \\\n",
       "0                                  Mejoramiento de la iluminación de la Iglesia San Miguel   \n",
       "1               Adquisición de Uniformes para la dirección de Seguridad Pública y Transito   \n",
       "2  PROYECTO EJECUTIVO JARDIN VECINAL COLONIA LAS AMERICAS DE ESTA CIUDAD DE SALAMANCA GTO.   \n",
       "3                                                   CONSTRUCCION DE DEPORTIVO BICENTENARIO   \n",
       "4                                         ACONDICIONAMIENTO DE CENTRO CULTURAL Y DEPORTIVO   \n",
       "\n",
       "  Clave de la UC  \\\n",
       "0      823001999   \n",
       "1      823001999   \n",
       "2      811027990   \n",
       "3      815060972   \n",
       "4      815060972   \n",
       "\n",
       "                                                Nombre de la UC  \\\n",
       "0           QROO-Cozumel-Dirección de Obras Públicas #823001999   \n",
       "1           QROO-Cozumel-Dirección de Obras Públicas #823001999   \n",
       "2  GTO-Salamanca-DIRECCION GENERAL DE OBRAS PUBLICAS #811027990   \n",
       "3     MEX-Nicolás Romero-Direccion de Obras Publicas #815060972   \n",
       "4     MEX-Nicolás Romero-Direccion de Obras Publicas #815060972   \n",
       "\n",
       "                  Operador                     Correo electrónico  \\\n",
       "0    Gabriel Caamal Caamal  compranetobraspublicas@cozumel.gob.mx   \n",
       "1    Gabriel Caamal Caamal  compranetobraspublicas@cozumel.gob.mx   \n",
       "2  Adriana Ortega González        adriana.ortega@salamanca.gob.mx   \n",
       "3    Paulino Mata González                    arqpau7@hotmail.com   \n",
       "4    Paulino Mata González                    arqpau7@hotmail.com   \n",
       "\n",
       "  Entidad federativa              Tipo de contratación  \\\n",
       "0       Quintana Roo                      Obra Pública   \n",
       "1       Quintana Roo                     Adquisiciones   \n",
       "2         Guanajuato  Servicios Relacionados con la OP   \n",
       "3             México                      Obra Pública   \n",
       "4             México                      Obra Pública   \n",
       "\n",
       "  Publicación del anuncio Vigencia del anuncio Clave COG Fecha de creación  \\\n",
       "0        2020-08-10 12:49     2011-08-17 07:00      6170   2011/07/2910:40   \n",
       "1        2020-08-14 11:19     2011-08-17 12:00      2830   2011/08/0112:14   \n",
       "2        2020-03-20 12:35     2011-08-23 23:00      6290   2011/08/2316:57   \n",
       "3        2020-06-08 10:26     2011-09-23 11:00      6120   2011/09/0109:55   \n",
       "4        2020-06-08 10:16     2011-09-23 09:00      6120   2011/09/0109:29   \n",
       "\n",
       "  Fecha de última modificacion  \\\n",
       "0             2020/08/31 12:51   \n",
       "1             2020/08/18 11:32   \n",
       "2             2020/03/24 14:26   \n",
       "3             2020/06/08 10:26   \n",
       "4             2020/06/08 10:15   \n",
       "\n",
       "                                                                            Dirección del anuncio  \\\n",
       "0    https://compranet.funcionpublica.gob.mx/esop/guest/go/opportunity/detail?opportunityId=29953   \n",
       "1  https://compranet.funcionpublica.gob.mx/esop/guest/go/opportunity/detail?opportunityId=1878185   \n",
       "2    https://compranet.funcionpublica.gob.mx/esop/guest/go/opportunity/detail?opportunityId=34849   \n",
       "3  https://compranet.funcionpublica.gob.mx/esop/guest/go/opportunity/detail?opportunityId=1855084   \n",
       "4  https://compranet.funcionpublica.gob.mx/esop/guest/go/opportunity/detail?opportunityId=1855076   \n",
       "\n",
       "                                                                                       nlp  \\\n",
       "0                                  mejoramiento de la iluminacion de la iglesia san miguel   \n",
       "1               adquisicion de uniformes para la direccion de seguridad publica y transito   \n",
       "2  proyecto ejecutivo jardin vecinal colonia las americas de esta ciudad de salamanca gto.   \n",
       "3                                                   construccion de deportivo bicentenario   \n",
       "4                                         acondicionamiento de centro cultural y deportivo   \n",
       "\n",
       "                                                                  nlp_lemma  \\\n",
       "0                             mejoramiento iluminacion iglesia santo miguel   \n",
       "1               adquisicion uniforme direccion seguridad publicar transitar   \n",
       "2  proyectar ejecutivo jardin vecinal colonia americas ciudad salamanca gto   \n",
       "3                                       construccion deportivo bicentenario   \n",
       "4                              acondicionamiento centrar cultural deportivo   \n",
       "\n",
       "                                                                               tokens  \\\n",
       "0                                 [mejoramiento, iluminacion, iglesia, santo, miguel]   \n",
       "1                  [adquisicion, uniforme, direccion, seguridad, publicar, transitar]   \n",
       "2  [proyectar, ejecutivo, jardin, vecinal, colonia, americas, ciudad, salamanca, gto]   \n",
       "3                                             [construccion, deportivo, bicentenario]   \n",
       "4                                   [acondicionamiento, centrar, cultural, deportivo]   \n",
       "\n",
       "                                                                     corpus  \n",
       "0                             mejoramiento iluminacion iglesia santo miguel  \n",
       "1               adquisicion uniforme direccion seguridad publicar transitar  \n",
       "2  proyectar ejecutivo jardin vecinal colonia americas ciudad salamanca gto  \n",
       "3                                       construccion deportivo bicentenario  \n",
       "4                              acondicionamiento centrar cultural deportivo  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Código del expediente</th>\n      <th>Número del procedimiento</th>\n      <th>Carácter del procedimiento</th>\n      <th>Forma del procedimiento</th>\n      <th>Artículo de excepción</th>\n      <th>REFERENCIA_EXPEDIENTE</th>\n      <th>Título del expediente</th>\n      <th>Plantilla del expediente</th>\n      <th>Descripción del Anuncio</th>\n      <th>Clave de la UC</th>\n      <th>Nombre de la UC</th>\n      <th>Operador</th>\n      <th>Correo electrónico</th>\n      <th>Entidad federativa</th>\n      <th>Tipo de contratación</th>\n      <th>Publicación del anuncio</th>\n      <th>Vigencia del anuncio</th>\n      <th>Clave COG</th>\n      <th>Fecha de creación</th>\n      <th>Fecha de última modificacion</th>\n      <th>Dirección del anuncio</th>\n      <th>nlp</th>\n      <th>nlp_lemma</th>\n      <th>tokens</th>\n      <th>corpus</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>50739</td>\n      <td>EO-823001999-N8-2011</td>\n      <td>Nacional</td>\n      <td>Presencial</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Mejoramiento de la iluminación de la Iglesia San Miguel</td>\n      <td>V20150817 30. Licitación Pública Nacional de Obra Pública (Norma Estatal)</td>\n      <td>Mejoramiento de la iluminación de la Iglesia San Miguel</td>\n      <td>823001999</td>\n      <td>QROO-Cozumel-Dirección de Obras Públicas #823001999</td>\n      <td>Gabriel Caamal Caamal</td>\n      <td>compranetobraspublicas@cozumel.gob.mx</td>\n      <td>Quintana Roo</td>\n      <td>Obra Pública</td>\n      <td>2020-08-10 12:49</td>\n      <td>2011-08-17 07:00</td>\n      <td>6170</td>\n      <td>2011/07/2910:40</td>\n      <td>2020/08/31 12:51</td>\n      <td>https://compranet.funcionpublica.gob.mx/esop/guest/go/opportunity/detail?opportunityId=29953</td>\n      <td>mejoramiento de la iluminacion de la iglesia san miguel</td>\n      <td>mejoramiento iluminacion iglesia santo miguel</td>\n      <td>[mejoramiento, iluminacion, iglesia, santo, miguel]</td>\n      <td>mejoramiento iluminacion iglesia santo miguel</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>51475</td>\n      <td>EA-823001999-N10-2011</td>\n      <td>Nacional</td>\n      <td>Presencial</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Adquisición de Uniformes para la dirección de Seguridad Pública y Transito</td>\n      <td>V20150817 28. Licitación Pública Nacional de Adquisiciones (Norma Estatal)</td>\n      <td>Adquisición de Uniformes para la dirección de Seguridad Pública y Transito</td>\n      <td>823001999</td>\n      <td>QROO-Cozumel-Dirección de Obras Públicas #823001999</td>\n      <td>Gabriel Caamal Caamal</td>\n      <td>compranetobraspublicas@cozumel.gob.mx</td>\n      <td>Quintana Roo</td>\n      <td>Adquisiciones</td>\n      <td>2020-08-14 11:19</td>\n      <td>2011-08-17 12:00</td>\n      <td>2830</td>\n      <td>2011/08/0112:14</td>\n      <td>2020/08/18 11:32</td>\n      <td>https://compranet.funcionpublica.gob.mx/esop/guest/go/opportunity/detail?opportunityId=1878185</td>\n      <td>adquisicion de uniformes para la direccion de seguridad publica y transito</td>\n      <td>adquisicion uniforme direccion seguridad publicar transitar</td>\n      <td>[adquisicion, uniforme, direccion, seguridad, publicar, transitar]</td>\n      <td>adquisicion uniforme direccion seguridad publicar transitar</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>61495</td>\n      <td>AO-811027990-N12-2011</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Art. 43 s/f</td>\n      <td>DGOP/HABITAT/PROY/007-11</td>\n      <td>PROYECTO EJECUTIVO JARDIN VECINAL COLONIA LAS AMERICAS</td>\n      <td>06. Adjudicación Directa LOPSRM</td>\n      <td>PROYECTO EJECUTIVO JARDIN VECINAL COLONIA LAS AMERICAS DE ESTA CIUDAD DE SALAMANCA GTO.</td>\n      <td>811027990</td>\n      <td>GTO-Salamanca-DIRECCION GENERAL DE OBRAS PUBLICAS #811027990</td>\n      <td>Adriana Ortega González</td>\n      <td>adriana.ortega@salamanca.gob.mx</td>\n      <td>Guanajuato</td>\n      <td>Servicios Relacionados con la OP</td>\n      <td>2020-03-20 12:35</td>\n      <td>2011-08-23 23:00</td>\n      <td>6290</td>\n      <td>2011/08/2316:57</td>\n      <td>2020/03/24 14:26</td>\n      <td>https://compranet.funcionpublica.gob.mx/esop/guest/go/opportunity/detail?opportunityId=34849</td>\n      <td>proyecto ejecutivo jardin vecinal colonia las americas de esta ciudad de salamanca gto.</td>\n      <td>proyectar ejecutivo jardin vecinal colonia americas ciudad salamanca gto</td>\n      <td>[proyectar, ejecutivo, jardin, vecinal, colonia, americas, ciudad, salamanca, gto]</td>\n      <td>proyectar ejecutivo jardin vecinal colonia americas ciudad salamanca gto</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>65885</td>\n      <td>IO-815060972-N7-2011</td>\n      <td>Nacional</td>\n      <td>Mixta</td>\n      <td>Art. 43 s/f</td>\n      <td>NR-OP-IR-PREP-15060-EMF-002/2011</td>\n      <td>CONSTRUCCION DE DEPORTIVO BICENTENARIO</td>\n      <td>V20151220 19. Invitación a cuando menos tres Nacional LOPSRM</td>\n      <td>CONSTRUCCION DE DEPORTIVO BICENTENARIO</td>\n      <td>815060972</td>\n      <td>MEX-Nicolás Romero-Direccion de Obras Publicas #815060972</td>\n      <td>Paulino Mata González</td>\n      <td>arqpau7@hotmail.com</td>\n      <td>México</td>\n      <td>Obra Pública</td>\n      <td>2020-06-08 10:26</td>\n      <td>2011-09-23 11:00</td>\n      <td>6120</td>\n      <td>2011/09/0109:55</td>\n      <td>2020/06/08 10:26</td>\n      <td>https://compranet.funcionpublica.gob.mx/esop/guest/go/opportunity/detail?opportunityId=1855084</td>\n      <td>construccion de deportivo bicentenario</td>\n      <td>construccion deportivo bicentenario</td>\n      <td>[construccion, deportivo, bicentenario]</td>\n      <td>construccion deportivo bicentenario</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>65850</td>\n      <td>IO-815060972-N8-2011</td>\n      <td>Nacional</td>\n      <td>Mixta</td>\n      <td>Art. 43 s/f</td>\n      <td>NR-OP-IR-PREP-15060-EMF-001/2011</td>\n      <td>ACONDICIONAMIENTO DE CENTRO CULTURAL Y DEPORTIVO</td>\n      <td>V20151220 19. Invitación a cuando menos tres Nacional LOPSRM</td>\n      <td>ACONDICIONAMIENTO DE CENTRO CULTURAL Y DEPORTIVO</td>\n      <td>815060972</td>\n      <td>MEX-Nicolás Romero-Direccion de Obras Publicas #815060972</td>\n      <td>Paulino Mata González</td>\n      <td>arqpau7@hotmail.com</td>\n      <td>México</td>\n      <td>Obra Pública</td>\n      <td>2020-06-08 10:16</td>\n      <td>2011-09-23 09:00</td>\n      <td>6120</td>\n      <td>2011/09/0109:29</td>\n      <td>2020/06/08 10:15</td>\n      <td>https://compranet.funcionpublica.gob.mx/esop/guest/go/opportunity/detail?opportunityId=1855076</td>\n      <td>acondicionamiento de centro cultural y deportivo</td>\n      <td>acondicionamiento centrar cultural deportivo</td>\n      <td>[acondicionamiento, centrar, cultural, deportivo]</td>\n      <td>acondicionamiento centrar cultural deportivo</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id2word = corpora.Dictionary(df['texts'])\n",
    "# corpus = [id2word.doc2bow(text) for text in df['texts']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lda(data, alfa, beta, num_topics=10):\n",
    "    \"\"\"\n",
    "    This function trains the lda model\n",
    "    We setup parameters like number of topics, the chunksize to use in Hoffman method\n",
    "    We also do 2 passes of the data since this is a small dataset, so we want the distributions to stabilize\n",
    "    \"\"\"\n",
    "    dictionary = corpora.Dictionary(data['tokens'])\n",
    "    corpus = [dictionary.doc2bow(doc) for doc in data['tokens']]\n",
    "    t1 = time.time()\n",
    "    # low alpha means each document is only represented by a small number of topics, and vice versa\n",
    "    # low eta means each topic is only represented by a small number of words, and vice versa\n",
    "    # lda = LdaModel(corpus=corpus, num_topics=num_topics, id2word=dictionary, alpha=alfa, eta=beta, minimum_probability=0.0, passes=10, random_state=0)\n",
    "                   \n",
    "    lda = LdaMulticore(corpus=corpus, num_topics=num_topics, id2word=dictionary, alpha=alfa, eta=beta, minimum_probability=0.0, passes=10, chunksize=300, random_state=0, workers=None)\n",
    "    coherence_model_lda = CoherenceModel(model=lda, texts=data['tokens'].tolist(), dictionary=dictionary, coherence='c_v')\n",
    "    coherence_lda = coherence_model_lda.get_coherence()\n",
    "    t2 = time.time()\n",
    "    print(\"Time to train LDA model on \", len(df), \"articles: \", (t2-t1)/60, \"min\")\n",
    "    return dictionary,corpus,lda,coherence_lda "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d48306e1b033420894d0672e7784bcdb"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "n LDA model on  96122 articles:  1.0908902684847515 min\n",
      "Coherence for 6 topics (Alpha=0.61, Beta=0.31): 0.5991389789325067\n",
      "Time to train LDA model on  96122 articles:  1.1061764081319174 min\n",
      "Coherence for 6 topics (Alpha=0.61, Beta=0.61): 0.5961713532853271\n",
      "Time to train LDA model on  96122 articles:  1.123843002319336 min\n",
      "Coherence for 6 topics (Alpha=0.61, Beta=0.9099999999999999): 0.6099456776260759\n",
      "Time to train LDA model on  96122 articles:  1.0785930315653482 min\n",
      "Coherence for 6 topics (Alpha=0.61, Beta=symmetric): 0.6048927746638019\n",
      "Time to train LDA model on  96122 articles:  1.0142196337382 min\n",
      "Coherence for 6 topics (Alpha=0.9099999999999999, Beta=0.01): 0.6324031755842584\n",
      "Time to train LDA model on  96122 articles:  1.0334973891576131 min\n",
      "Coherence for 6 topics (Alpha=0.9099999999999999, Beta=0.31): 0.6379672949826902\n",
      "Time to train LDA model on  96122 articles:  1.0542896469434102 min\n",
      "Coherence for 6 topics (Alpha=0.9099999999999999, Beta=0.61): 0.607419843980743\n",
      "Time to train LDA model on  96122 articles:  1.0588878870010376 min\n",
      "Coherence for 6 topics (Alpha=0.9099999999999999, Beta=0.9099999999999999): 0.5918413560866874\n",
      "Time to train LDA model on  96122 articles:  1.0494659344355266 min\n",
      "Coherence for 6 topics (Alpha=0.9099999999999999, Beta=symmetric): 0.6315501094569027\n",
      "Time to train LDA model on  96122 articles:  1.0495056668917337 min\n",
      "Coherence for 6 topics (Alpha=symmetric, Beta=0.01): 0.5991981989095349\n",
      "Time to train LDA model on  96122 articles:  1.0706369002660117 min\n",
      "Coherence for 6 topics (Alpha=symmetric, Beta=0.31): 0.6076650843742132\n",
      "Time to train LDA model on  96122 articles:  1.0820051352183024 min\n",
      "Coherence for 6 topics (Alpha=symmetric, Beta=0.61): 0.6172351521201334\n",
      "Time to train LDA model on  96122 articles:  1.0853916565577189 min\n",
      "Coherence for 6 topics (Alpha=symmetric, Beta=0.9099999999999999): 0.6136055285307774\n",
      "Time to train LDA model on  96122 articles:  1.0490987380345662 min\n",
      "Coherence for 6 topics (Alpha=symmetric, Beta=symmetric): 0.5984020900344663\n",
      "Time to train LDA model on  96122 articles:  1.040212913354238 min\n",
      "Coherence for 6 topics (Alpha=asymmetric, Beta=0.01): 0.5376524970736283\n",
      "Time to train LDA model on  96122 articles:  1.0577757755915325 min\n",
      "Coherence for 6 topics (Alpha=asymmetric, Beta=0.31): 0.5439412706764483\n",
      "Time to train LDA model on  96122 articles:  1.0724832574526468 min\n",
      "Coherence for 6 topics (Alpha=asymmetric, Beta=0.61): 0.5604639136598051\n",
      "Time to train LDA model on  96122 articles:  1.0658849120140075 min\n",
      "Coherence for 6 topics (Alpha=asymmetric, Beta=0.9099999999999999): 0.6097660555063603\n",
      "Time to train LDA model on  96122 articles:  1.0408793528874716 min\n",
      "Coherence for 6 topics (Alpha=asymmetric, Beta=symmetric): 0.5483144330711305\n",
      "Time to train LDA model on  96122 articles:  1.020916473865509 min\n",
      "Coherence for 7 topics (Alpha=0.01, Beta=0.01): 0.6446813820750422\n",
      "Time to train LDA model on  96122 articles:  1.0239074230194092 min\n",
      "Coherence for 7 topics (Alpha=0.01, Beta=0.31): 0.5829054788058486\n",
      "Time to train LDA model on  96122 articles:  1.0190471887588501 min\n",
      "Coherence for 7 topics (Alpha=0.01, Beta=0.61): 0.5651909439537965\n",
      "Time to train LDA model on  96122 articles:  1.0217424273490905 min\n",
      "Coherence for 7 topics (Alpha=0.01, Beta=0.9099999999999999): 0.5589417501570664\n",
      "Time to train LDA model on  96122 articles:  1.01542223294576 min\n",
      "Coherence for 7 topics (Alpha=0.01, Beta=symmetric): 0.6101888438550063\n",
      "Time to train LDA model on  96122 articles:  1.1740374207496642 min\n",
      "Coherence for 7 topics (Alpha=0.31, Beta=0.01): 0.6283483716933557\n",
      "Time to train LDA model on  96122 articles:  1.18709876537323 min\n",
      "Coherence for 7 topics (Alpha=0.31, Beta=0.31): 0.5696112021033299\n",
      "Time to train LDA model on  96122 articles:  1.2046632289886474 min\n",
      "Coherence for 7 topics (Alpha=0.31, Beta=0.61): 0.5505418859331911\n",
      "Time to train LDA model on  96122 articles:  1.2141126632690429 min\n",
      "Coherence for 7 topics (Alpha=0.31, Beta=0.9099999999999999): 0.5644508671240471\n",
      "Time to train LDA model on  96122 articles:  1.187818467617035 min\n",
      "Coherence for 7 topics (Alpha=0.31, Beta=symmetric): 0.6378764666760884\n",
      "Time to train LDA model on  96122 articles:  1.1419068336486817 min\n",
      "Coherence for 7 topics (Alpha=0.61, Beta=0.01): 0.6063694974202819\n",
      "Time to train LDA model on  96122 articles:  1.0983255704243977 min\n",
      "Coherence for 7 topics (Alpha=0.61, Beta=0.31): 0.608336058321178\n",
      "Time to train LDA model on  96122 articles:  1.1269721706708273 min\n",
      "Coherence for 7 topics (Alpha=0.61, Beta=0.61): 0.6149579238456376\n",
      "Time to train LDA model on  96122 articles:  1.1308315436045329 min\n",
      "Coherence for 7 topics (Alpha=0.61, Beta=0.9099999999999999): 0.6200826167162943\n",
      "Time to train LDA model on  96122 articles:  1.0849858204523721 min\n",
      "Coherence for 7 topics (Alpha=0.61, Beta=symmetric): 0.6065864479202919\n",
      "Time to train LDA model on  96122 articles:  1.0133269747098288 min\n",
      "Coherence for 7 topics (Alpha=0.9099999999999999, Beta=0.01): 0.6397742273354872\n",
      "Time to train LDA model on  96122 articles:  1.0439303636550903 min\n",
      "Coherence for 7 topics (Alpha=0.9099999999999999, Beta=0.31): 0.5806554292165292\n",
      "Time to train LDA model on  96122 articles:  1.055813237031301 min\n",
      "Coherence for 7 topics (Alpha=0.9099999999999999, Beta=0.61): 0.5794105876220056\n",
      "Time to train LDA model on  96122 articles:  1.0616850932439168 min\n",
      "Coherence for 7 topics (Alpha=0.9099999999999999, Beta=0.9099999999999999): 0.5633284346202793\n",
      "Time to train LDA model on  96122 articles:  1.0161323229471841 min\n",
      "Coherence for 7 topics (Alpha=0.9099999999999999, Beta=symmetric): 0.6405554024348994\n",
      "Time to train LDA model on  96122 articles:  1.0573000232378642 min\n",
      "Coherence for 7 topics (Alpha=symmetric, Beta=0.01): 0.6181246198966862\n",
      "Time to train LDA model on  96122 articles:  1.0661452213923137 min\n",
      "Coherence for 7 topics (Alpha=symmetric, Beta=0.31): 0.5675331009435217\n",
      "Time to train LDA model on  96122 articles:  1.081891703605652 min\n",
      "Coherence for 7 topics (Alpha=symmetric, Beta=0.61): 0.5688190621875366\n",
      "Time to train LDA model on  96122 articles:  1.0777531584103903 min\n",
      "Coherence for 7 topics (Alpha=symmetric, Beta=0.9099999999999999): 0.5826721108803132\n",
      "Time to train LDA model on  96122 articles:  1.0556801915168763 min\n",
      "Coherence for 7 topics (Alpha=symmetric, Beta=symmetric): 0.583230381779902\n",
      "Time to train LDA model on  96122 articles:  1.0437276204427084 min\n",
      "Coherence for 7 topics (Alpha=asymmetric, Beta=0.01): 0.5621735893890272\n",
      "Time to train LDA model on  96122 articles:  1.0530429164568582 min\n",
      "Coherence for 7 topics (Alpha=asymmetric, Beta=0.31): 0.5112070520265999\n",
      "Time to train LDA model on  96122 articles:  1.0582772533098856 min\n",
      "Coherence for 7 topics (Alpha=asymmetric, Beta=0.61): 0.49042438830963736\n",
      "Time to train LDA model on  96122 articles:  1.0653567512830098 min\n",
      "Coherence for 7 topics (Alpha=asymmetric, Beta=0.9099999999999999): 0.596090184003707\n",
      "Time to train LDA model on  96122 articles:  1.040701985359192 min\n",
      "Coherence for 7 topics (Alpha=asymmetric, Beta=symmetric): 0.5209180802599469\n",
      "Time to train LDA model on  96122 articles:  1.0203739166259767 min\n",
      "Coherence for 8 topics (Alpha=0.01, Beta=0.01): 0.6150148989012535\n",
      "Time to train LDA model on  96122 articles:  1.0318788488705952 min\n",
      "Coherence for 8 topics (Alpha=0.01, Beta=0.31): 0.539569130614618\n",
      "Time to train LDA model on  96122 articles:  1.0492152174313862 min\n",
      "Coherence for 8 topics (Alpha=0.01, Beta=0.61): 0.5410645384854629\n",
      "Time to train LDA model on  96122 articles:  1.0609079798062642 min\n",
      "Coherence for 8 topics (Alpha=0.01, Beta=0.9099999999999999): 0.5244277269231712\n",
      "Time to train LDA model on  96122 articles:  1.0180110375086466 min\n",
      "Coherence for 8 topics (Alpha=0.01, Beta=symmetric): 0.5546100697612457\n",
      "Time to train LDA model on  96122 articles:  1.1708877285321553 min\n",
      "Coherence for 8 topics (Alpha=0.31, Beta=0.01): 0.6302897675140106\n",
      "Time to train LDA model on  96122 articles:  1.2101259708404541 min\n",
      "Coherence for 8 topics (Alpha=0.31, Beta=0.31): 0.5463409846421088\n",
      "Time to train LDA model on  96122 articles:  1.239337400595347 min\n",
      "Coherence for 8 topics (Alpha=0.31, Beta=0.61): 0.5394174421008927\n",
      "Time to train LDA model on  96122 articles:  1.2468621969223022 min\n",
      "Coherence for 8 topics (Alpha=0.31, Beta=0.9099999999999999): 0.5170589174385387\n",
      "Time to train LDA model on  96122 articles:  1.1832705895105997 min\n",
      "Coherence for 8 topics (Alpha=0.31, Beta=symmetric): 0.5332910500474065\n",
      "Time to train LDA model on  96122 articles:  1.0684064030647278 min\n",
      "Coherence for 8 topics (Alpha=0.61, Beta=0.01): 0.6116984165012894\n",
      "Time to train LDA model on  96122 articles:  1.0976133783658346 min\n",
      "Coherence for 8 topics (Alpha=0.61, Beta=0.31): 0.5859865099777835\n",
      "Time to train LDA model on  96122 articles:  1.1080536166826884 min\n",
      "Coherence for 8 topics (Alpha=0.61, Beta=0.61): 0.5974518640938142\n",
      "Time to train LDA model on  96122 articles:  1.123267161846161 min\n",
      "Coherence for 8 topics (Alpha=0.61, Beta=0.9099999999999999): 0.6008906005499546\n",
      "Time to train LDA model on  96122 articles:  1.0699372172355652 min\n",
      "Coherence for 8 topics (Alpha=0.61, Beta=symmetric): 0.5988891588455545\n",
      "Time to train LDA model on  96122 articles:  0.9959681987762451 min\n",
      "Coherence for 8 topics (Alpha=0.9099999999999999, Beta=0.01): 0.5920403673559397\n",
      "Time to train LDA model on  96122 articles:  1.0144951860109965 min\n",
      "Coherence for 8 topics (Alpha=0.9099999999999999, Beta=0.31): 0.6026325804604851\n",
      "Time to train LDA model on  96122 articles:  1.032584305604299 min\n",
      "Coherence for 8 topics (Alpha=0.9099999999999999, Beta=0.61): 0.5738615185547118\n",
      "Time to train LDA model on  96122 articles:  1.03098863363266 min\n",
      "Coherence for 8 topics (Alpha=0.9099999999999999, Beta=0.9099999999999999): 0.551133520538054\n",
      "Time to train LDA model on  96122 articles:  1.0014475305875143 min\n",
      "Coherence for 8 topics (Alpha=0.9099999999999999, Beta=symmetric): 0.5923213410393179\n",
      "Time to train LDA model on  96122 articles:  1.046408236026764 min\n",
      "Coherence for 8 topics (Alpha=symmetric, Beta=0.01): 0.554028687187258\n",
      "Time to train LDA model on  96122 articles:  1.0641563653945922 min\n",
      "Coherence for 8 topics (Alpha=symmetric, Beta=0.31): 0.5213671696788803\n",
      "Time to train LDA model on  96122 articles:  1.079898234208425 min\n",
      "Coherence for 8 topics (Alpha=symmetric, Beta=0.61): 0.5236962850420959\n",
      "Time to train LDA model on  96122 articles:  1.0925134579340616 min\n",
      "Coherence for 8 topics (Alpha=symmetric, Beta=0.9099999999999999): 0.5343499777656452\n",
      "Time to train LDA model on  96122 articles:  1.0497649868329366 min\n",
      "Coherence for 8 topics (Alpha=symmetric, Beta=symmetric): 0.5560324884417132\n",
      "Time to train LDA model on  96122 articles:  1.0521732767422993 min\n",
      "Coherence for 8 topics (Alpha=asymmetric, Beta=0.01): 0.5491274368823379\n",
      "Time to train LDA model on  96122 articles:  1.0616276184717814 min\n",
      "Coherence for 8 topics (Alpha=asymmetric, Beta=0.31): 0.5092293154504568\n",
      "Time to train LDA model on  96122 articles:  1.0671496232350668 min\n",
      "Coherence for 8 topics (Alpha=asymmetric, Beta=0.61): 0.4609777876799202\n",
      "Time to train LDA model on  96122 articles:  1.0613757689793906 min\n",
      "Coherence for 8 topics (Alpha=asymmetric, Beta=0.9099999999999999): 0.48644875828609213\n",
      "Time to train LDA model on  96122 articles:  1.0487151185671488 min\n",
      "Coherence for 8 topics (Alpha=asymmetric, Beta=symmetric): 0.5432987786834982\n",
      "Time to train LDA model on  96122 articles:  1.0270911852518718 min\n",
      "Coherence for 9 topics (Alpha=0.01, Beta=0.01): 0.6105144292467637\n",
      "Time to train LDA model on  96122 articles:  1.043194341659546 min\n",
      "Coherence for 9 topics (Alpha=0.01, Beta=0.31): 0.5978336063670853\n",
      "Time to train LDA model on  96122 articles:  1.0493743141492209 min\n",
      "Coherence for 9 topics (Alpha=0.01, Beta=0.61): 0.5934102728706736\n",
      "Time to train LDA model on  96122 articles:  1.046084741751353 min\n",
      "Coherence for 9 topics (Alpha=0.01, Beta=0.9099999999999999): 0.577797775609881\n",
      "Time to train LDA model on  96122 articles:  1.0232832868893942 min\n",
      "Coherence for 9 topics (Alpha=0.01, Beta=symmetric): 0.6108688449255193\n",
      "Time to train LDA model on  96122 articles:  1.1890235463778178 min\n",
      "Coherence for 9 topics (Alpha=0.31, Beta=0.01): 0.5987012364207942\n",
      "Time to train LDA model on  96122 articles:  1.2003801266352336 min\n",
      "Coherence for 9 topics (Alpha=0.31, Beta=0.31): 0.6083627005766288\n",
      "Time to train LDA model on  96122 articles:  1.2189197262128195 min\n",
      "Coherence for 9 topics (Alpha=0.31, Beta=0.61): 0.6142849842674518\n",
      "Time to train LDA model on  96122 articles:  1.2417389114697774 min\n",
      "Coherence for 9 topics (Alpha=0.31, Beta=0.9099999999999999): 0.5946377560965961\n",
      "Time to train LDA model on  96122 articles:  1.1880455136299133 min\n",
      "Coherence for 9 topics (Alpha=0.31, Beta=symmetric): 0.6007133485781445\n",
      "Time to train LDA model on  96122 articles:  1.0443819920221964 min\n",
      "Coherence for 9 topics (Alpha=0.61, Beta=0.01): 0.6184475860201083\n",
      "Time to train LDA model on  96122 articles:  1.0760228514671326 min\n",
      "Coherence for 9 topics (Alpha=0.61, Beta=0.31): 0.6102918462358008\n",
      "Time to train LDA model on  96122 articles:  1.0990958372751871 min\n",
      "Coherence for 9 topics (Alpha=0.61, Beta=0.61): 0.611673360163802\n",
      "Time to train LDA model on  96122 articles:  1.106204088528951 min\n",
      "Coherence for 9 topics (Alpha=0.61, Beta=0.9099999999999999): 0.5853601603226963\n",
      "Time to train LDA model on  96122 articles:  1.0518223166465759 min\n",
      "Coherence for 9 topics (Alpha=0.61, Beta=symmetric): 0.621695893523327\n",
      "Time to train LDA model on  96122 articles:  0.9955503344535828 min\n",
      "Coherence for 9 topics (Alpha=0.9099999999999999, Beta=0.01): 0.6044794670642514\n",
      "Time to train LDA model on  96122 articles:  1.0274168729782105 min\n",
      "Coherence for 9 topics (Alpha=0.9099999999999999, Beta=0.31): 0.5949011658902514\n",
      "Time to train LDA model on  96122 articles:  1.0205106178919474 min\n",
      "Coherence for 9 topics (Alpha=0.9099999999999999, Beta=0.61): 0.6102608340152664\n",
      "Time to train LDA model on  96122 articles:  1.0211255311965943 min\n",
      "Coherence for 9 topics (Alpha=0.9099999999999999, Beta=0.9099999999999999): 0.5854977218046408\n",
      "Time to train LDA model on  96122 articles:  0.9963843743006389 min\n",
      "Coherence for 9 topics (Alpha=0.9099999999999999, Beta=symmetric): 0.589374867957886\n",
      "Time to train LDA model on  96122 articles:  1.0520244121551514 min\n",
      "Coherence for 9 topics (Alpha=symmetric, Beta=0.01): 0.6309830761912288\n",
      "Time to train LDA model on  96122 articles:  1.078208315372467 min\n",
      "Coherence for 9 topics (Alpha=symmetric, Beta=0.31): 0.6091208995182236\n",
      "Time to train LDA model on  96122 articles:  1.0806721051534016 min\n",
      "Coherence for 9 topics (Alpha=symmetric, Beta=0.61): 0.5997407241575924\n",
      "Time to train LDA model on  96122 articles:  1.075760026772817 min\n",
      "Coherence for 9 topics (Alpha=symmetric, Beta=0.9099999999999999): 0.5770694663855676\n",
      "Time to train LDA model on  96122 articles:  1.0561805844306946 min\n",
      "Coherence for 9 topics (Alpha=symmetric, Beta=symmetric): 0.6195065646415162\n",
      "Time to train LDA model on  96122 articles:  1.0550766269365945 min\n",
      "Coherence for 9 topics (Alpha=asymmetric, Beta=0.01): 0.6480070438123694\n",
      "Time to train LDA model on  96122 articles:  1.0554728945096334 min\n",
      "Coherence for 9 topics (Alpha=asymmetric, Beta=0.31): 0.5678627514819543\n",
      "Time to train LDA model on  96122 articles:  1.0536410530408225 min\n",
      "Coherence for 9 topics (Alpha=asymmetric, Beta=0.61): 0.5547733415037585\n",
      "Time to train LDA model on  96122 articles:  1.0581197301546732 min\n",
      "Coherence for 9 topics (Alpha=asymmetric, Beta=0.9099999999999999): 0.5704876254550952\n",
      "Time to train LDA model on  96122 articles:  1.0489552696545918 min\n",
      "Coherence for 9 topics (Alpha=asymmetric, Beta=symmetric): 0.6276379916119121\n",
      "Time to train LDA model on  96122 articles:  1.2180916825930277 min\n",
      "Coherence for 10 topics (Alpha=0.01, Beta=0.01): 0.6240612521004005\n",
      "Time to train LDA model on  96122 articles:  1.2269815921783447 min\n",
      "Coherence for 10 topics (Alpha=0.01, Beta=0.31): 0.5903264327607943\n",
      "Time to train LDA model on  96122 articles:  1.1867566227912902 min\n",
      "Coherence for 10 topics (Alpha=0.01, Beta=0.61): 0.5809486544363993\n",
      "Time to train LDA model on  96122 articles:  1.1984702348709106 min\n",
      "Coherence for 10 topics (Alpha=0.01, Beta=0.9099999999999999): 0.5394475982207648\n",
      "Time to train LDA model on  96122 articles:  1.220093047618866 min\n",
      "Coherence for 10 topics (Alpha=0.01, Beta=symmetric): 0.6172937572390016\n",
      "Time to train LDA model on  96122 articles:  1.3633671601613362 min\n",
      "Coherence for 10 topics (Alpha=0.31, Beta=0.01): 0.612205577782903\n",
      "Time to train LDA model on  96122 articles:  1.3410978237787883 min\n",
      "Coherence for 10 topics (Alpha=0.31, Beta=0.31): 0.6021567589294371\n",
      "Time to train LDA model on  96122 articles:  1.3614142656326294 min\n",
      "Coherence for 10 topics (Alpha=0.31, Beta=0.61): 0.601224111601591\n",
      "Time to train LDA model on  96122 articles:  1.4241918802261353 min\n",
      "Coherence for 10 topics (Alpha=0.31, Beta=0.9099999999999999): 0.5978328926808366\n",
      "Time to train LDA model on  96122 articles:  1.3679861505826314 min\n",
      "Coherence for 10 topics (Alpha=0.31, Beta=symmetric): 0.6218946429575162\n",
      "Time to train LDA model on  96122 articles:  1.1686018506685893 min\n",
      "Coherence for 10 topics (Alpha=0.61, Beta=0.01): 0.6364253851749965\n",
      "Time to train LDA model on  96122 articles:  1.196704375743866 min\n",
      "Coherence for 10 topics (Alpha=0.61, Beta=0.31): 0.6345279049754848\n",
      "Time to train LDA model on  96122 articles:  1.2615363796552022 min\n",
      "Coherence for 10 topics (Alpha=0.61, Beta=0.61): 0.6197824690252849\n",
      "Time to train LDA model on  96122 articles:  1.2635327299435934 min\n",
      "Coherence for 10 topics (Alpha=0.61, Beta=0.9099999999999999): 0.5729753673769954\n",
      "Time to train LDA model on  96122 articles:  1.1793523987134298 min\n",
      "Coherence for 10 topics (Alpha=0.61, Beta=symmetric): 0.6395941950449943\n",
      "Time to train LDA model on  96122 articles:  1.1180692116419475 min\n",
      "Coherence for 10 topics (Alpha=0.9099999999999999, Beta=0.01): 0.6102954951408994\n",
      "Time to train LDA model on  96122 articles:  1.1777479688326518 min\n",
      "Coherence for 10 topics (Alpha=0.9099999999999999, Beta=0.31): 0.6032200016114159\n",
      "Time to train LDA model on  96122 articles:  1.1838464180628459 min\n",
      "Coherence for 10 topics (Alpha=0.9099999999999999, Beta=0.61): 0.6375495462941615\n",
      "Time to train LDA model on  96122 articles:  1.1383261720339457 min\n",
      "Coherence for 10 topics (Alpha=0.9099999999999999, Beta=0.9099999999999999): 0.6015483134466011\n",
      "Time to train LDA model on  96122 articles:  1.1200856248537698 min\n",
      "Coherence for 10 topics (Alpha=0.9099999999999999, Beta=symmetric): 0.608684162936852\n",
      "Time to train LDA model on  96122 articles:  1.2246926108996072 min\n",
      "Coherence for 10 topics (Alpha=symmetric, Beta=0.01): 0.6303649956918693\n",
      "Time to train LDA model on  96122 articles:  1.2330282966295878 min\n",
      "Coherence for 10 topics (Alpha=symmetric, Beta=0.31): 0.6036261674131859\n",
      "Time to train LDA model on  96122 articles:  1.2104880531628928 min\n",
      "Coherence for 10 topics (Alpha=symmetric, Beta=0.61): 0.5858240269530379\n",
      "Time to train LDA model on  96122 articles:  1.2088364958763123 min\n",
      "Coherence for 10 topics (Alpha=symmetric, Beta=0.9099999999999999): 0.5465823078957478\n",
      "Time to train LDA model on  96122 articles:  1.220063066482544 min\n",
      "Coherence for 10 topics (Alpha=symmetric, Beta=symmetric): 0.6247323139709946\n",
      "Time to train LDA model on  96122 articles:  1.2310548861821493 min\n",
      "Coherence for 10 topics (Alpha=asymmetric, Beta=0.01): 0.6377102813064486\n",
      "Time to train LDA model on  96122 articles:  1.1924227237701417 min\n",
      "Coherence for 10 topics (Alpha=asymmetric, Beta=0.31): 0.5708126053095313\n",
      "Time to train LDA model on  96122 articles:  1.1840850909550984 min\n",
      "Coherence for 10 topics (Alpha=asymmetric, Beta=0.61): 0.5361842825805196\n",
      "Time to train LDA model on  96122 articles:  1.2246923168500266 min\n",
      "Coherence for 10 topics (Alpha=asymmetric, Beta=0.9099999999999999): 0.5463868655942776\n",
      "Time to train LDA model on  96122 articles:  1.2199742476145425 min\n",
      "Coherence for 10 topics (Alpha=asymmetric, Beta=symmetric): 0.6260127584979401\n",
      "\n",
      "Best num of topics: 5 (Alpha=0.9099999999999999, Beta=symmetric) with coherence = 0.682207418502587\n"
     ]
    }
   ],
   "source": [
    "kas = range(2, 11, 1)\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = list(np.arange(0.01, 1.0, 0.3))\n",
    "alpha.append('symmetric')\n",
    "alpha.append('asymmetric')\n",
    "# Beta parameter\n",
    "beta = list(np.arange(0.01, 1.0, 0.3))\n",
    "beta.append('symmetric')\n",
    "\n",
    "best_i = 0\n",
    "best_coherence = 0\n",
    "\n",
    "model_results = {'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "with tqdm(total = len(kas), bar_format='{bar}|{desc}{percentage:3.0f}% {r_bar}') as pbar:\n",
    "    for i in kas:\n",
    "        for a in alpha:\n",
    "            for b in beta:\n",
    "                dictionary,corpus,lda,coherence = train_lda(df, alfa=a, beta=b, num_topics=i)\n",
    "                print(f\"Coherence for {i} topics (Alpha={a}, Beta={b}): {coherence}\")\n",
    "                if coherence > best_coherence:\n",
    "                    best_i = i\n",
    "                    best_coherence = coherence\n",
    "                    best_alfa = a\n",
    "                    best_beta = b\n",
    "                    \n",
    "                model_results['Topics'].append(i)\n",
    "                model_results['Alpha'].append(a)\n",
    "                model_results['Beta'].append(b)\n",
    "                model_results['Coherence'].append(coherence)\n",
    "        pbar.update(1)\n",
    "            \n",
    "model_results_df = pd.DataFrame(model_results)\n",
    "                \n",
    "print(f\"Best num of topics: {best_i} (Alpha={best_alfa}, Beta={best_beta}) with coherence = {best_coherence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Time to train LDA model on  96122 articles:  1.3706595460573832 min\n"
     ]
    }
   ],
   "source": [
    "dictionary,corpus,lda,coherence = train_lda(df, alfa=0.9099999999999999, beta='symmetric', num_topics=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.054*\"servicio\" + 0.023*\"profesional\" + 0.016*\"apoyar\" + 0.013*\"nacional\" + 0.012*\"elaboracion\" + 0.009*\"e\" + 0.009*\"informacion\" + 0.007*\"publicar\" + 0.007*\"control\" + 0.007*\"seguimiento\" + 0.006*\"actividad\" + 0.006*\"coadyuvar\" + 0.006*\"sistema\" + 0.006*\"administrativo\" + 0.005*\"atencion\" + 0.005*\"produccion\" + 0.005*\"programar\" + 0.005*\"analisis\" + 0.004*\"instituto\" + 0.004*\"administracion\"'),\n",
       " (1,\n",
       "  '0.059*\"adquisicion\" + 0.056*\"material\" + 0.026*\"curacion\" + 0.019*\"medicamento\" + 0.014*\"laboratorio\" + 0.011*\"accesorio\" + 0.011*\"adjudicacion\" + 0.011*\"directo\" + 0.010*\"grupo\" + 0.009*\"suministro\" + 0.008*\"envasar\" + 0.008*\"medicos\" + 0.007*\"miligramo\" + 0.006*\"alto\" + 0.006*\"contener\" + 0.006*\"vegetal\" + 0.006*\"equipar\" + 0.006*\"mililitro\" + 0.006*\"covid-19\" + 0.006*\"suministrar\"'),\n",
       " (2,\n",
       "  '0.040*\"rural\" + 0.038*\"establecer\" + 0.037*\"programar\" + 0.036*\"desarrollar\" + 0.028*\"integral\" + 0.019*\"direccion\" + 0.016*\"ley\" + 0.016*\"linear\" + 0.015*\"tecnica\" + 0.015*\"presentar\" + 0.015*\"formar\" + 0.014*\"ejecucion\" + 0.014*\"conformar\" + 0.014*\"proponer\" + 0.014*\"proveedor\" + 0.014*\"capacidad\" + 0.013*\"colaboracion\" + 0.013*\"terminos\" + 0.013*\"extensionismo\" + 0.013*\"convenio\"'),\n",
       " (3,\n",
       "  '0.027*\"kilómetro\" + 0.025*\"municipio\" + 0.015*\"construccion\" + 0.014*\"santo\" + 0.013*\"obrar\" + 0.012*\"aguar\" + 0.011*\"localidad\" + 0.010*\"rehabilitacion\" + 0.010*\"ubicar\" + 0.009*\"conservacion\" + 0.008*\"sanitario\" + 0.007*\"trabajo\" + 0.006*\"caminar\" + 0.006*\"centrar\" + 0.006*\"proyectar\" + 0.006*\"escuela\" + 0.006*\"edificio\" + 0.006*\"sistema\" + 0.005*\"red\" + 0.005*\"tramar\"'),\n",
       " (4,\n",
       "  '0.067*\"servicio\" + 0.032*\"mantenimiento\" + 0.013*\"harina\" + 0.013*\"preventivo\" + 0.012*\"correctivo\" + 0.012*\"producto\" + 0.011*\"equipar\" + 0.010*\"limpieza\" + 0.010*\"contratacion\" + 0.009*\"equipo\" + 0.009*\"suministrar\" + 0.009*\"medicamento\" + 0.009*\"maiz\" + 0.008*\"medicar\" + 0.008*\"s18\" + 0.008*\"galleta\" + 0.007*\"oficina\" + 0.007*\"hospital\" + 0.007*\"medicinar\" + 0.007*\"avaluos\"')]"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# show_topics method shows the the top num_words contributing to num_topics number of random topics\n",
    "lda.show_topics(num_topics=5, num_words=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Showing topic: 0\n\t[('servicio', 0.05419069), ('profesional', 0.023073554), ('apoyar', 0.015945783), ('nacional', 0.013459353), ('elaboracion', 0.012354963), ('e', 0.009488567), ('informacion', 0.009044206), ('publicar', 0.007168093), ('control', 0.006739752), ('seguimiento', 0.0066884444), ('actividad', 0.006308964), ('coadyuvar', 0.0058020013), ('sistema', 0.0056813005), ('administrativo', 0.005599497), ('atencion', 0.0053372723), ('produccion', 0.0050806287), ('programar', 0.005032489), ('analisis', 0.0045469594), ('instituto', 0.004474118), ('administracion', 0.0043973215)]\n\n\nShowing topic: 1\n\t[('adquisicion', 0.058639824), ('material', 0.055856295), ('curacion', 0.02592756), ('medicamento', 0.019294241), ('laboratorio', 0.0144603755), ('accesorio', 0.01148835), ('adjudicacion', 0.0114041725), ('directo', 0.010892282), ('grupo', 0.009802117), ('suministro', 0.008662567), ('envasar', 0.008417626), ('medicos', 0.0075705573), ('miligramo', 0.006756567), ('alto', 0.0064423466), ('contener', 0.0063667297), ('vegetal', 0.0061999517), ('equipar', 0.0061089816), ('mililitro', 0.005943311), ('covid-19', 0.0057502403), ('suministrar', 0.0055909147)]\n\n\nShowing topic: 2\n\t[('rural', 0.03981418), ('establecer', 0.03824936), ('programar', 0.036713988), ('desarrollar', 0.03644783), ('integral', 0.0284332), ('direccion', 0.019431984), ('ley', 0.016383275), ('linear', 0.01582908), ('tecnica', 0.015394413), ('presentar', 0.014921731), ('formar', 0.014775789), ('ejecucion', 0.0144728925), ('conformar', 0.0144585455), ('proponer', 0.013801556), ('proveedor', 0.0137926955), ('capacidad', 0.013787335), ('colaboracion', 0.012938117), ('terminos', 0.01293302), ('extensionismo', 0.01292044), ('convenio', 0.01284196)]\n\n\nShowing topic: 3\n\t[('kilómetro', 0.027199054), ('municipio', 0.02505064), ('construccion', 0.015384701), ('santo', 0.01350462), ('obrar', 0.013128697), ('aguar', 0.011753262), ('localidad', 0.010578479), ('rehabilitacion', 0.010376423), ('ubicar', 0.009642909), ('conservacion', 0.008562783), ('sanitario', 0.007922549), ('trabajo', 0.0068126707), ('caminar', 0.006456493), ('centrar', 0.006239112), ('proyectar', 0.00619508), ('escuela', 0.0061011277), ('edificio', 0.0057497746), ('sistema', 0.005616682), ('red', 0.004926762), ('tramar', 0.004771796)]\n\n\nShowing topic: 4\n\t[('servicio', 0.067040905), ('mantenimiento', 0.031688314), ('harina', 0.013201217), ('preventivo', 0.012530829), ('correctivo', 0.0120164985), ('producto', 0.011807926), ('equipar', 0.011468657), ('limpieza', 0.010087654), ('contratacion', 0.009889848), ('equipo', 0.009465202), ('suministrar', 0.009463028), ('medicamento', 0.0088289995), ('maiz', 0.008702323), ('medicar', 0.008092495), ('s18', 0.00804498), ('galleta', 0.007827142), ('oficina', 0.0074276635), ('hospital', 0.0072476882), ('medicinar', 0.0069566797), ('avaluos', 0.0068355133)]\n\n\n"
     ]
    }
   ],
   "source": [
    "lda.\n",
    "for i in range(5):\n",
    "    print(f\"Showing topic: {i}\")\n",
    "    print(f\"\\t{lda.show_topic(topicid=i, topn=20)}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics_sentences(ldamodel, corpus, texts):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num) + 1, round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=lda, corpus=corpus, texts=df['corpus'])\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "df_dominant_topic['expediente'] = df['Código del expediente']\n",
    "df_dominant_topic['corpus'] = df['corpus']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head(10)\n",
    "df_dominant_topic.to_csv(\"dataset_lda.csv\", encoding='utf8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select and article at random from train_df\n",
    "random_article_index = np.random.randint(len(df))\n",
    "bow = dictionary.doc2bow(df.iloc[random_article_index,16])\n",
    "print(random_article_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[random_article_index,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the topic contributions for the document chosen at random above\n",
    "doc_distribution = np.array([tup[1] for tup in lda.get_document_topics(bow=bow)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar plot of topic distribution for this document\n",
    "fig, ax = plt.subplots(figsize=(12,6));\n",
    "# the histogram of the data\n",
    "patches = ax.bar(np.arange(len(doc_distribution)), doc_distribution)\n",
    "ax.set_xlabel('Topic ID', fontsize=15)\n",
    "ax.set_ylabel('Topic Contribution', fontsize=15)\n",
    "ax.set_title(\"Topic Distribution for Article \" + str(random_article_index), fontsize=20)\n",
    "ax.set_xticks(np.linspace(10,5,1))\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the top 5 contributing topics and their words\n",
    "for i in doc_distribution.argsort()[-5:][::-1]:\n",
    "    print(i, lda.show_topic(topicid=i, topn=10), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarity Queries on Unseen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select and article at random from test_df\n",
    "random_article_index = np.random.randint(len(df))\n",
    "print(random_article_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bow = dictionary.doc2bow(df.iloc[random_article_index,16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[random_article_index,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_doc_distribution = np.array([tup[1] for tup in lda.get_document_topics(bow=new_bow)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_doc_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar plot of topic distribution for this document\n",
    "fig, ax = plt.subplots(figsize=(12,6));\n",
    "# the histogram of the data\n",
    "patches = ax.bar(np.arange(len(new_doc_distribution)), new_doc_distribution)\n",
    "ax.set_xlabel('Topic ID', fontsize=15)\n",
    "ax.set_ylabel('Topic Contribution', fontsize=15)\n",
    "ax.set_title(\"Topic Distribution for an Unseen Article\", fontsize=20)\n",
    "ax.set_xticks(np.linspace(10,5,1))\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the top 8 contributing topics and their words\n",
    "for i in new_doc_distribution.argsort()[-5:][::-1]:\n",
    "    print(i, lda.show_topic(topicid=i, topn=10), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarity Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to use nested list comprehension here\n",
    "# this may take 1-2 minutes...\n",
    "doc_topic_dist = np.array([[tup[1] for tup in lst] for lst in lda[corpus]])\n",
    "doc_topic_dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topic_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "braycurtis(u, v[, w])\n",
    "\n",
    "Compute the Bray-Curtis distance between two 1-D arrays.\n",
    "\n",
    "canberra(u, v[, w])\n",
    "\n",
    "Compute the Canberra distance between two 1-D arrays.\n",
    "\n",
    "chebyshev(u, v[, w])\n",
    "\n",
    "Compute the Chebyshev distance.\n",
    "\n",
    "cityblock(u, v[, w])\n",
    "\n",
    "Compute the City Block (Manhattan) distance.\n",
    "\n",
    "correlation(u, v[, w, centered])\n",
    "\n",
    "Compute the correlation distance between two 1-D arrays.\n",
    "\n",
    "cosine(u, v[, w])\n",
    "\n",
    "Compute the Cosine distance between 1-D arrays.\n",
    "\n",
    "euclidean(u, v[, w])\n",
    "\n",
    "Computes the Euclidean distance between two 1-D arrays.\n",
    "\n",
    "jensenshannon(p, q[, base])\n",
    "\n",
    "Compute the Jensen-Shannon distance (metric) between two 1-D probability arrays.\n",
    "\n",
    "mahalanobis(u, v, VI)\n",
    "\n",
    "Compute the Mahalanobis distance between two 1-D arrays.\n",
    "\n",
    "minkowski(u, v[, p, w])\n",
    "\n",
    "Compute the Minkowski distance between two 1-D arrays.\n",
    "\n",
    "seuclidean(u, v, V)\n",
    "\n",
    "Return the standardized Euclidean distance between two 1-D arrays.\n",
    "\n",
    "sqeuclidean(u, v[, w])\n",
    "\n",
    "Compute the squared Euclidean distance between two 1-D arrays.\n",
    "\n",
    "wminkowski(u, v, p, w)\n",
    "\n",
    "Compute the weighted Minkowski distance between two 1-D arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcula_distancia(query, matrix, metrica):\n",
    "    \"\"\"\n",
    "    This function implements a Jensen-Shannon similarity\n",
    "    between the input query (an LDA topic distribution for a document)\n",
    "    and the entire corpus of topic distributions.\n",
    "    It returns an array of length M where M is the number of documents in the corpus\n",
    "    \"\"\"\n",
    "    \n",
    "    sim = [metrica(data,query) for data in matrix]\n",
    "    sim = np.array(sim, dtype=np.float64)\n",
    "    \n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_similar_documents(query,matrix,k=15, metrica=distance.cosine):\n",
    "    \"\"\"\n",
    "    This function implements the Jensen-Shannon distance above\n",
    "    and retruns the top k indices of the smallest jensen shannon distances\n",
    "    \"\"\"\n",
    "    sims = calcula_distancia(query,matrix, metrica) # list of jensen shannon distances\n",
    "    sims = np.array(sims, dtype=np.float32)\n",
    "    return sims.argsort()[:k] # the top k positional index of the smallest Jensen Shannon distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is surprisingly fast\n",
    "metrica=distance.jensenshannon\n",
    "most_sim_ids = get_most_similar_documents(new_doc_distribution,doc_topic_dist, metrica=metrica)\n",
    "most_similar_df = df.iloc[most_sim_ids]\n",
    "most_similar_df['titulo_caso']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is surprisingly fast\n",
    "metrica=distance.euclidean\n",
    "most_sim_ids = get_most_similar_documents(new_doc_distribution,doc_topic_dist, metrica=metrica)\n",
    "most_similar_df = df.iloc[most_sim_ids]\n",
    "most_similar_df['titulo_caso']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is surprisingly fast\n",
    "metrica=distance.cosine\n",
    "most_sim_ids = get_most_similar_documents(new_doc_distribution,doc_topic_dist)\n",
    "most_similar_df = df.iloc[most_sim_ids]\n",
    "most_similar_df['titulo_caso']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is surprisingly fast\n",
    "metrica=distance.chebyshev\n",
    "most_sim_ids = get_most_similar_documents(new_doc_distribution,doc_topic_dist)\n",
    "most_similar_df = df.iloc[most_sim_ids]\n",
    "most_similar_df['titulo_caso']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el1544819293513184721773010802\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el1544819293513184721773010802_data = {\"mdsDat\": {\"x\": [-0.013900485004404805, -0.02207408013151789, 0.04107484561236032, -0.012258426452173858, 0.004866856840200286, -0.008525698994125535, 0.00801905928170469, 0.0027979288479568197], \"y\": [0.02005859443457002, -0.03260355710410813, -0.008138023592703608, 0.005057229944424198, 0.007334694732272238, 0.008919994844615474, -0.00047798166178665574, -0.0001509515972835658], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [22.04168379409213, 21.691308812252526, 21.368547204897013, 12.377306482332786, 9.441226271221078, 7.359997674564471, 3.711568445131001, 2.0083613155089983]}, \"tinfo\": {\"Term\": [\"personar\", \"sector\", \"hogar\", \"medir\", \"propagacion\", \"residente\", \"covid-19\", \"paquete\", \"anciano\", \"personal\", \"ingresar\", \"trabajador\", \"caso\", \"evitar\", \"avanzar\", \"salud\", \"informacion\", \"restaurante\", \"necesidad\", \"muerte\", \"bill\\u00f3n\", \"adecuar\", \"dato\", \"actual\", \"contagio\", \"pandemia\", \"establecimiento\", \"asociar\", \"movilidad\", \"estimulos\", \"bill\\u00f3n\", \"necesario\", \"r\", \"cuidar\", \"capacitaci\\u00f3n\", \"capacitar\", \"herramienta\", \"economica\", \"transferencia\", \"municipio\", \"gasto\", \"deuda\", \"constante\", \"enfermedad\", \"creacion\", \"economico\", \"area\", \"reduccion\", \"renegociacion\", \"transmision\", \"avanzar\", \"capacidad\", \"profesional\", \"cuomo\", \"numerar\", \"indicar\", \"validar\", \"totalidad\", \"pertinente\", \"poblacional\", \"social\", \"entidad\", \"fondo\", \"prueba\", \"salud\", \"informacion\", \"paciente\", \"personal\", \"covid-19\", \"programar\", \"poblacion\", \"medir\", \"proteger\", \"cerrar\", \"contagiar\", \"tasar\", \"personar\", \"manejar\", \"hospital\", \"contagio\", \"salario\", \"propagacion\", \"radioterapia\", \"movilidad\", \"seguridad\", \"madre\", \"calamidad\", \"areas\", \"actividad\", \"operador\", \"paciente\", \"vulnerable\", \"jornada\", \"reducci\\u00f3n\", \"medicosreducir\", \"sintomas\", \"proteccion\", \"empleador\", \"indicaci\\u00f3n\", \"instalar\", \"virus\", \"vehiculos\", \"sospechoso\", \"respiratorio\", \"triaje\", \"familia\", \"mascarilla\", \"desechable\", \"esteriles\", \"publicar\", \"covid-19\", \"situacion\", \"mejorar\", \"personar\", \"servicio\", \"personal\", \"proteger\", \"afectar\", \"salud\", \"aumentar\", \"sanitario\", \"gobernar\", \"ingresar\", \"contagiar\", \"riesgo\", \"trabajador\", \"estimulos\", \"economia\", \"aspecto\", \"sector\", \"impuesto\", \"liquidez\", \"obrar\", \"decretar\", \"federal\", \"especial\", \"practicamente\", \"esperar\", \"productivo\", \"jefe\", \"actual\", \"cuyo\", \"condonacion\", \"nominar\", \"fiscal\", \"potosi\", \"plantilla\", \"luis\", \"prioridad\", \"vacaci\\u00f3n\", \"importante\", \"perder\", \"desocupacion\", \"cano\", \"soto\", \"contingencia\", \"empresa\", \"distinto\", \"meter\", \"gobernar\", \"medir\", \"impactar\", \"paquete\", \"trabajador\", \"publicar\", \"afectar\", \"poder\", \"tasar\", \"sanitario\", \"cerrar\", \"evitar\", \"problema\", \"california\", \"covid\", \"plataforma\", \"diagnosticar\", \"habilidad\", \"corps\", \"gratis\", \"ofrecer\", \"hara\", \"informal\", \"alianza\", \"health\", \"united\", \"personar\", \"facilitar\", \"hotel\", \"interesar\", \"foco\", \"atender\", \"modular\", \"municipioreducir\", \"concurrir\", \"pacienteinstalar\", \"hospitalreducir\", \"positivo\", \"relevante\", \"revision\", \"humanar\", \"busqueda\", \"aprender\", \"hospital\", \"personal\", \"trabajador\", \"riesgo\", \"informacion\", \"caso\", \"salud\", \"poder\", \"infeccion\", \"aumentar\", \"poblacion\", \"alto\", \"covid-19\", \"considerar\", \"virus\", \"gobernador\", \"gobernar\", \"contagiar\", \"numerar\", \"pandemia\", \"ingresar\", \"ciudad\", \"dato\", \"comerciante\", \"alimenticio\", \"cubrebocas\", \"elemento\", \"policia\", \"confiable\", \"institucion\", \"aislamiento\", \"ingresar\", \"contagio\", \"necesidad\", \"resultar\", \"controlar\", \"pequenos\", \"satisfacer\", \"relevante\", \"durar\", \"coronavirusgarantizar\", \"disminucion\", \"colimar\", \"suficiente\", \"sostenerseentregar\", \"permanencia\", \"secretario\", \"beneficio\", \"frontero\", \"contingenciasatisfacer\", \"reforzar\", \"microempresa\", \"campar\", \"medir\", \"informacion\", \"contar\", \"covid-19\", \"sector\", \"establecer\", \"alto\", \"contagiar\", \"pandemia\", \"salud\", \"poblacion\", \"sanitario\", \"publicar\", \"negocio\", \"personar\", \"establecimiento\", \"restaurante\", \"salubridad\", \"probar\", \"tecnologia\", \"venta\", \"domiciliar\", \"estricto\", \"dinero\", \"camacampana\", \"honorario\", \"tradicional\", \"tecnologias\", \"pico\", \"covid-19reunir\", \"construir\", \"bitcoins\", \"innovadorconstruir\", \"involucrar\", \"donacion\", \"periodo\", \"pretratamiento\", \"transparente\", \"campana\", \"suspension\", \"infectar\", \"disposici\\u00f3n\", \"resguardar\", \"autoridad\", \"esencialcontrolar\", \"cantidad\", \"poner\", \"necesidad\", \"medicar\", \"caso\", \"avanzar\", \"considerar\", \"virus\", \"propagacion\", \"infeccion\", \"actividad\", \"sanitario\", \"entregar\", \"personar\", \"e\", \"numerar\", \"centro\", \"alto\", \"contagio\", \"crear\", \"medir\", \"evitar\", \"gobernar\", \"aglomeraci\\u00f3n\", \"privar\", \"paquete\", \"permiso\", \"destinatario\", \"tianguis\", \"proposito\", \"rapida\", \"casino\", \"feriar\", \"virusmedir\", \"esencialmeter\", \"drasticamente\", \"mayormente\", \"nocturno\", \"excepcion\", \"extender\", \"confirmaresperar\", \"mencionar\", \"realizacion\", \"fungir\", \"restaurantero\", \"antro\", \"vender\", \"bar\", \"cabildo\", \"publicos\", \"cancelacion\", \"otorgar\", \"lanzar\", \"evitar\", \"operar\", \"caso\", \"medir\", \"optar\", \"avanzar\", \"sector\", \"consistir\", \"poder\", \"distinto\", \"ciudad\", \"solicitar\", \"covid-19\", \"pandemia\", \"masivo\", \"trabajador\", \"gobernar\", \"aumentar\", \"confirmar\", \"foco\", \"numerar\", \"cerrar\", \"servicio\", \"contagiar\", \"hogar\", \"anciano\", \"residente\", \"adecuar\", \"muerte\", \"canadabeneficiar\", \"estimar\", \"ancianogarantizar\", \"dotacion\", \"alla\", \"continuo\", \"remuneracion\", \"canadaordenar\", \"mortalidad\", \"movimiento\", \"emplear\", \"asociar\", \"representar\", \"ayudar\", \"sitio\", \"prevenir\", \"limitar\", \"pobrezapoblacion\", \"prestador\", \"afecto\", \"alimenticio\", \"sonororeducir\", \"alimento\", \"microempresa\", \"pobreza\", \"quedar\", \"actual\", \"propagacion\", \"pandemia\", \"trabajador\", \"covid-19\", \"vulnerable\", \"familia\", \"personal\", \"ingresar\", \"salud\"], \"Freq\": [8.0, 6.0, 1.0, 8.0, 4.0, 2.0, 11.0, 3.0, 1.0, 7.0, 4.0, 6.0, 5.0, 5.0, 4.0, 12.0, 4.0, 2.0, 2.0, 1.0, 4.0, 1.0, 2.0, 3.0, 3.0, 5.0, 1.0, 2.0, 4.0, 3.0, 3.103995125199269, 1.641395313567734, 2.9740467136668367, 1.2290619481013576, 1.224552957549344, 1.2237856451435325, 1.2166682695421418, 3.177661019951213, 1.1499217412829092, 1.4992506903911482, 1.1414150487590686, 1.129158653623504, 1.1212454462320838, 1.320116968077091, 1.0411761364327148, 1.6069062691950993, 1.2507158598723713, 1.7635386311158396, 1.038878211448041, 1.1451894753996963, 1.8472378187377263, 1.0293147835659988, 1.6801418790931346, 1.227886147025013, 1.5069183925131002, 0.9159841726187831, 0.7668766448020954, 0.76687447602763, 0.766873445859759, 0.7668729578855044, 2.003139086786225, 1.0851148564666884, 1.2373832104084181, 1.055755072143134, 4.182694963675144, 1.8132820760061008, 1.9610511988809105, 2.146947702171287, 2.835706012463606, 1.4719863759559348, 1.6775415185092792, 2.1528578294665865, 1.41681980207655, 1.4468750039323923, 1.3940983110750085, 1.3371838134153413, 1.4904018736954114, 1.2540272531646646, 1.2512138104895967, 1.2451170601515609, 1.7218012666990083, 2.713583286978565, 2.2397726198828822, 2.5027304947980418, 1.792711342970439, 1.3904092097510397, 1.1201390110128198, 1.4157528435097564, 3.0633311741147504, 1.2775788216703552, 3.0702620986011944, 1.5920212317145486, 1.0045643405201534, 0.990988807837176, 1.0212591520529608, 1.6201001838269717, 0.9393723729935207, 1.405113680201802, 0.9522713327066752, 0.9331282661149283, 2.041580066006445, 0.9278005207650218, 0.9455420995314243, 0.9460394980507215, 0.9380546564270581, 2.1033550198905338, 0.9335714534246561, 0.9302488825389408, 0.9268646303950934, 3.0844509222711705, 4.408069253958218, 1.4413434157309604, 1.4116640590714655, 2.7868288205756384, 1.4083001894886964, 2.443293025824205, 1.738887508776502, 1.459805000463829, 3.4900589788394885, 1.5383185190223068, 1.6649694573788256, 1.8459841010104068, 1.4220709038691195, 1.443222879949339, 1.408554064424849, 1.4526447454865095, 2.2884333098029344, 2.4978124029528432, 2.0257808558192836, 3.8223283171202165, 2.1102460536848198, 1.738564722417832, 1.8704496998691154, 1.3593144512486677, 2.0094861575660357, 1.3434206025724496, 1.5107859713816116, 1.5096357759391035, 1.4664859431853057, 1.128674351199177, 1.9494806684307362, 1.1207033001949447, 1.1173276694793848, 1.0813915522058426, 2.591462764533107, 1.0490956705220762, 1.046172296528358, 1.0343342508109161, 1.049854057316908, 1.0310354679948601, 1.0309616687808358, 0.9775879115804373, 1.1666854668864135, 0.9523187242918134, 0.9386907848165663, 1.4221304078878532, 1.5680545819728786, 1.337918040662956, 1.5336559483248446, 2.654613656066711, 2.8030242959780964, 1.373459510857513, 1.4271081753865067, 2.0191961156916034, 2.2063616454201718, 1.4267576816834335, 1.4905709789828032, 1.4358328824667232, 1.4566718041180027, 1.446044717298491, 1.3835592802161327, 1.343657453896092, 0.9163976108268898, 1.009540114280356, 1.1574213870495966, 0.7157483025420581, 0.7017256705298995, 0.6796095360978418, 0.6762063606366916, 0.6819839281096625, 0.665460856039509, 0.6528352260927259, 0.6619178098720486, 0.6614359044433422, 0.6543025593143001, 2.723061854653249, 0.6745271814476586, 0.9174681058277311, 0.6876279577250198, 0.7064507672637041, 0.6686899390542766, 0.46489031256034224, 0.46488927738315144, 0.46488580649492345, 0.46488337078388625, 0.4648800216812102, 0.6511702349204845, 0.6667735216102222, 0.5638214355256105, 0.4458342532434597, 0.4433296420303138, 0.44155863653517896, 1.0860087751504672, 1.8602656578733219, 1.499890274938211, 1.1437747070360271, 1.1384647351894193, 1.230733731772176, 2.289406887309009, 1.060297774798633, 0.8370465295153777, 0.9248627418582869, 0.8972809327515694, 0.8423521170821188, 1.0877428796233888, 0.7577753395258853, 0.7879260321707423, 0.7097789228249093, 0.7907442107335375, 0.7372264633607021, 0.706821665161891, 0.7201756944943433, 0.6931036797077079, 0.6890032819621644, 0.9507379745495167, 0.5931627377136619, 0.5777440558188782, 0.591912865558982, 0.581079773187063, 0.5719703236776812, 0.5337741860404822, 0.5547129469553248, 0.5873197049944134, 1.2413180852051076, 1.014335746721466, 0.7604224697269757, 0.6002961917864096, 0.5742429831840296, 0.3728431713941335, 0.3689930644471089, 0.5552404581248479, 0.3682053045250245, 0.3675094886339404, 0.3673269940151981, 0.37478467911012214, 0.3665062327119438, 0.3659795111602671, 0.37328027132024055, 0.3736874354403462, 0.37336250769654067, 0.37299784359581634, 0.3641353819039866, 0.37314866060448426, 0.3634726835143439, 0.3719506709871257, 1.573941723230568, 0.9345914043446515, 0.6015714246083923, 1.241764451528883, 0.8287763888766182, 0.5800040814396837, 0.5857620676720608, 0.5716547552277612, 0.5825940744240793, 0.8011325183466613, 0.5820041834446883, 0.5791272804933872, 0.5632990656249587, 0.44492494606892996, 0.543823466579549, 0.6854585929828937, 0.811725828989891, 0.495508157790823, 0.4469907269882484, 0.447076940770916, 0.44145501278337923, 0.4569461196107619, 0.466927003414711, 0.31678792775649456, 0.31677145263212925, 0.3167676506803526, 0.31675584652531286, 0.31674425962466035, 0.31673665572110715, 0.3167356056582355, 0.31673444696817027, 0.3167221720952915, 0.31672054268738725, 0.31671540100022266, 0.3167141336829638, 0.3167130474110276, 0.3167079419329276, 0.3166419690173374, 0.3166089463504777, 0.521752813650355, 0.43982144083669705, 0.30971075746513077, 0.30952956730617703, 0.30949788437470527, 0.3093358850199573, 0.6431340346975085, 0.5370005955640348, 0.5433480807868063, 0.540116747658271, 0.7534117823128068, 0.63245388143918, 0.5103222999475824, 0.5578970639639457, 0.522404576812059, 0.45997077139890785, 0.5571938839305961, 0.525853635045668, 0.438799005481306, 0.5019690860127956, 0.34409756462225094, 0.3681607691795593, 0.3437703795150755, 0.3671634267058939, 0.35663763268969567, 0.3481019612786963, 0.3809870336931212, 0.3611412799280064, 0.359412260887199, 0.24695254323945268, 0.25661313368789207, 0.3734873207422762, 0.15719064801514634, 0.1571228126886327, 0.15651589193959908, 0.15639083025688258, 0.15626450864481764, 0.15592189916127117, 0.15521482315895968, 0.15526368650586425, 0.1550607648413835, 0.15502311303969546, 0.15481608290994808, 0.15451470415783303, 0.1545287459791221, 0.15432363313316586, 0.15428784383573202, 0.15384580949273285, 0.1539121109922136, 0.15345935811982991, 0.15335889244917636, 0.15329889059643778, 0.15210477886157323, 0.152232981237738, 0.1515113612683826, 0.2434591426129975, 0.15028520350443825, 0.171945972772212, 0.17689002683470353, 0.40456119564074977, 0.17314980787487427, 0.2933737453501462, 0.3764611557211893, 0.16973819309699367, 0.2353846753953198, 0.27584940630259364, 0.17278444662367343, 0.2116112145984434, 0.18597367920063296, 0.19038965852751907, 0.16972024366873986, 0.25703747424047624, 0.20741254569439407, 0.18040327591335797, 0.20886809276905913, 0.20105687774582207, 0.18322827489054497, 0.16868564081537185, 0.16693373644613987, 0.1727042859013599, 0.17994058968495186, 0.16568724634408705, 0.16520310479706624, 0.27808471063436535, 0.22029208147497797, 0.21812298279859135, 0.15661321852565616, 0.15603290370795206, 0.09849901672300188, 0.09844590872332266, 0.09833433746148494, 0.09829819438002883, 0.09824544208044049, 0.09740544643528166, 0.09725031179286986, 0.09708286597509057, 0.09707986228543429, 0.09667211141459485, 0.10041218918400412, 0.11590281945546121, 0.10198837533113483, 0.09719056405816098, 0.09608331907805824, 0.100336326259067, 0.09735964016802345, 0.05359608442752592, 0.04891941867716916, 0.04789869280389267, 0.05464578009709255, 0.051776826671072695, 0.05169253563009346, 0.046576881624527805, 0.050532592693471816, 0.050499226048836145, 0.10651832467456383, 0.11055141039383118, 0.11424754932145934, 0.1112826309750889, 0.15408740206091254, 0.07013455776390966, 0.0838547748177813, 0.09827004467005933, 0.0802404666721705, 0.09727743392479907], \"Total\": [8.0, 6.0, 1.0, 8.0, 4.0, 2.0, 11.0, 3.0, 1.0, 7.0, 4.0, 6.0, 5.0, 5.0, 4.0, 12.0, 4.0, 2.0, 2.0, 1.0, 4.0, 1.0, 2.0, 3.0, 3.0, 5.0, 1.0, 2.0, 4.0, 3.0, 4.525098182476945, 2.7707899545409176, 5.175707169161998, 2.331402116240907, 2.33075498138575, 2.330696911983773, 2.3295973037351, 6.138862140532498, 2.2822296066331464, 2.9772793491369463, 2.2773081603672543, 2.2700445089826196, 2.308359990661419, 2.7270023683616174, 2.258141853991214, 3.4898308882037328, 2.7164666369364494, 3.8337366606231265, 2.2783184733881336, 2.5600525772686726, 4.266052968317785, 2.3998730326296442, 3.9877487426507847, 2.939929834602387, 3.6174863675024853, 2.206485931126174, 1.856931066766762, 1.8569296590277917, 1.8569281126130734, 1.8569277021380826, 4.87477750411186, 2.6275806843826865, 3.03835645393215, 2.580790373241558, 12.121698289321069, 4.9075333160988865, 6.359086850245426, 7.427543554987214, 11.47263918745022, 4.220403012928397, 5.380688796456441, 8.952692790036796, 4.804438341161969, 5.468386043834562, 4.824325360406587, 4.5890796760107175, 8.603733805146003, 3.5683851833497005, 4.132373283090454, 3.9226320043074163, 2.8996001716022337, 4.586014180884757, 3.805922832505054, 4.53399941735056, 3.2932059811326266, 2.6168060490942198, 2.2385896547031843, 2.835243165424086, 6.166064189856894, 2.5966727377617667, 6.359086850245426, 3.3402737252935344, 2.149028269662695, 2.1385626650825746, 2.2081897248257527, 3.6714376052811093, 2.137872601446877, 3.2364777260320796, 2.195515275566595, 2.1591402624201668, 4.725163558817041, 2.147567351811292, 2.1962313269126685, 2.2009118077515883, 2.195037161957189, 4.944214734574556, 2.200397072907795, 2.1951538006158158, 2.1947355185345945, 7.305577766600484, 11.47263918745022, 3.500828795369199, 3.4628631202978655, 8.603733805146003, 3.6613525361935597, 7.427543554987214, 4.804438341161969, 3.838724023379081, 12.121698289321069, 4.311899748980214, 5.521192182906205, 7.32913651552343, 4.646444775725295, 4.824325360406587, 4.724352779622634, 6.226209210609517, 3.471859511730623, 4.158938133130729, 3.444361527194253, 6.610143545245444, 3.791877581182618, 3.208048892742858, 3.4516727351150895, 2.5729529914452907, 3.887496387225562, 2.6048595757357393, 2.9364298776576696, 2.952344194769506, 2.8703984123942834, 2.25391418410301, 3.895307388618765, 2.2465742150853067, 2.2476542601145097, 2.221465546740712, 5.374223006746136, 2.1869442360998894, 2.1838843780527073, 2.174423400362661, 2.2072029337762338, 2.215779118517694, 2.21946258383852, 2.1509242240236026, 2.5781290336902476, 2.1135395651513087, 2.106622635534718, 3.218180279392409, 3.564519121330884, 3.0328034597162135, 3.5603504866939852, 7.32913651552343, 8.952692790036796, 3.3486393637719134, 3.5689771171432034, 6.226209210609517, 7.305577766600484, 3.838724023379081, 4.655796700654923, 4.5890796760107175, 5.521192182906205, 5.468386043834562, 5.214045044064946, 4.817745842998821, 2.2027627652382655, 2.5607041311924936, 3.0002347418824713, 1.9445016217166509, 1.9788259093001586, 1.9366143462019556, 1.9342231159703718, 1.956766966642296, 1.92966128490045, 1.8940449618325559, 1.9249926109787452, 1.9330653143399381, 1.9289988893738996, 8.603733805146003, 2.1839924097503176, 3.0603398581758974, 2.3192261337173954, 2.5021633393240035, 2.4011945278835025, 1.6693730307881778, 1.669372604563883, 1.6693696946984677, 1.6693686194594513, 1.6693641712026452, 2.3397432672760496, 2.420985778804752, 2.052878621314819, 1.676158131069638, 1.677199603767937, 1.6788275592263588, 4.132373283090454, 7.427543554987214, 6.226209210609517, 4.724352779622634, 4.9075333160988865, 5.4841016312572455, 12.121698289321069, 4.655796700654923, 3.599655651182016, 4.311899748980214, 5.380688796456441, 4.678916631601699, 11.47263918745022, 3.5390707891214577, 4.725163558817041, 3.023380938488772, 7.32913651552343, 4.824325360406587, 3.6174863675024853, 5.136369004823579, 4.646444775725295, 3.316650145958195, 2.72645440979199, 1.8362112943769426, 1.8247291745651284, 1.9089069115441737, 1.9292067341421093, 1.9377303969219224, 1.8582643287821896, 1.9539076877641193, 2.1294956162314085, 4.646444775725295, 3.9226320043074163, 2.97771009432639, 2.4373759364272383, 2.37360674072469, 1.6093613229540642, 1.6064942426581785, 2.420985778804752, 1.6059076655592572, 1.6053894175009533, 1.6052533638963038, 1.6406949352466818, 1.6046429777350761, 1.6042509044499338, 1.6401133118564941, 1.6425952045618974, 1.6420706388318418, 1.6415381552931736, 1.602876673018861, 1.643385868378043, 1.6023836422547788, 1.6431206997002632, 8.952692790036796, 4.9075333160988865, 3.553377585203706, 11.47263918745022, 6.610143545245444, 4.023739211882768, 4.678916631601699, 4.824325360406587, 5.136369004823579, 12.121698289321069, 5.380688796456441, 5.521192182906205, 7.305577766600484, 3.315421600064216, 8.603733805146003, 1.9827718191671082, 2.708240214389245, 1.7827465898052826, 1.8046512580013314, 1.853410490113088, 1.8600879395554706, 1.9995055740081158, 2.058155257510053, 1.5774022935431062, 1.5773947223944351, 1.5773934841983062, 1.5773872005986795, 1.5773818022662354, 1.5773789048654407, 1.5773775686116602, 1.577377392679478, 1.577370455369322, 1.5773697769441166, 1.5773670514705078, 1.5773658301399058, 1.5773662110307727, 1.5773638348586607, 1.577330530110902, 1.5773167941104922, 2.633405966401943, 2.2207221411189453, 1.5807856773400926, 1.5808685743051223, 1.5808841300003673, 1.5809600920783697, 3.2870224039083036, 2.8356805010331585, 2.97771009432639, 3.02568947028554, 5.4841016312572455, 4.266052968317785, 3.5390707891214577, 4.725163558817041, 4.586014180884757, 3.599655651182016, 6.166064189856894, 5.521192182906205, 3.5400280163807305, 8.603733805146003, 2.273193726632874, 3.6174863675024853, 2.5438279611730668, 4.678916631601699, 3.9226320043074163, 3.4869213368404672, 8.952692790036796, 5.214045044064946, 7.32913651552343, 2.068038908226459, 2.2889828406640804, 3.5689771171432034, 1.5131603354321088, 1.5127770212612626, 1.5143949490947486, 1.516295357476331, 1.518085811863664, 1.5157595441833145, 1.5165571518679366, 1.5181894492075678, 1.5187294202280066, 1.5186494053909672, 1.5192819371716555, 1.5191253883200218, 1.520302872165252, 1.5192323484875203, 1.5193818307488967, 1.5217440503808322, 1.523713261875319, 1.5206673833895687, 1.524386551765952, 1.5242056622825755, 1.5197720502826009, 1.527460847999912, 1.5273453050259613, 2.4720467155067793, 1.5269674823463562, 1.754482780366485, 1.899701228092141, 5.214045044064946, 1.8774134412462347, 5.4841016312572455, 8.952692790036796, 1.8844792965978197, 4.266052968317785, 6.610143545245444, 2.1814641295037616, 4.655796700654923, 3.0328034597162135, 3.316650145958195, 2.1694244267672627, 11.47263918745022, 5.136369004823579, 3.0812138418331743, 6.226209210609517, 7.32913651552343, 4.311899748980214, 2.6640978804609405, 2.5021633393240035, 3.6174863675024853, 5.468386043834562, 3.6613525361935597, 4.824325360406587, 1.6986666269097983, 1.606542189380157, 2.0064083315691064, 1.548886155698848, 1.8183503298334083, 1.4586757566103343, 1.4589866133287426, 1.4596364931993873, 1.4598494911573823, 1.4601579873392596, 1.465084265841256, 1.4659855784711144, 1.466970218291376, 1.4669919831431344, 1.4693735703687603, 1.8396154405016998, 2.1639551531728785, 1.9046087330935728, 2.1441881591704703, 2.151068300218917, 2.36924321902129, 2.573339916636566, 1.7217855427292479, 1.5955446133103908, 1.5985246676759384, 1.8247291745651284, 1.7324442104901157, 1.7329459948956198, 1.6023836422547788, 1.7397387220040745, 1.7399336537668184, 3.895307388618765, 4.586014180884757, 5.136369004823579, 6.226209210609517, 11.47263918745022, 3.3402737252935344, 4.944214734574556, 7.427543554987214, 4.646444775725295, 12.121698289321069], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.010900020599365, -5.648099899291992, -5.053699970245361, -5.937399864196777, -5.941100120544434, -5.941699981689453, -5.947500228881836, -4.987500190734863, -6.003900051116943, -5.738699913024902, -6.01140022277832, -6.022200107574463, -6.029200077056885, -5.865900039672852, -6.103300094604492, -5.669300079345703, -5.919899940490723, -5.576300144195557, -6.105500221252441, -6.0081000328063965, -5.529900074005127, -6.114699840545654, -5.624800205230713, -5.938300132751465, -5.73360013961792, -6.231400012969971, -6.40910005569458, -6.40910005569458, -6.40910005569458, -6.40910005569458, -5.44890022277832, -6.0619001388549805, -5.930600166320801, -6.089399814605713, -4.712699890136719, -5.548500061035156, -5.470099925994873, -5.3796000480651855, -5.10129976272583, -5.756999969482422, -5.626299858093262, -5.376800060272217, -5.795199871063232, -5.774199962615967, -5.811399936676025, -5.853099822998047, -5.74459981918335, -5.917300224304199, -5.91949987411499, -5.9243998527526855, -5.584199905395508, -5.129300117492676, -5.321199893951416, -5.21019983291626, -5.543900012969971, -5.797999858856201, -6.014200210571289, -5.779900074005127, -5.0081000328063965, -5.882599830627441, -5.005799770355225, -5.662600040435791, -6.1230998039245605, -6.13670015335083, -6.106599807739258, -5.645100116729736, -6.190100193023682, -5.787499904632568, -6.176499843597412, -6.196800231933594, -5.413899898529053, -6.202499866485596, -6.183599948883057, -6.18310022354126, -6.1915998458862305, -5.384099960327148, -6.196300029754639, -6.199900150299072, -6.20359992980957, -5.001200199127197, -4.644199848175049, -5.76200008392334, -5.782800197601318, -5.102700233459473, -5.785200119018555, -5.234300136566162, -5.574399948120117, -5.749300003051758, -4.877699851989746, -5.696899890899658, -5.617800235748291, -5.514599800109863, -5.7754998207092285, -5.760700225830078, -5.784999847412109, -5.754199981689453, -5.2846999168396, -5.197199821472168, -5.406700134277344, -4.7718000411987305, -5.365799903869629, -5.559599876403809, -5.486400127410889, -5.805600166320801, -5.414700031280518, -5.817399978637695, -5.699999809265137, -5.700699806213379, -5.729700088500977, -5.991600036621094, -5.445099830627441, -5.998700141906738, -6.001699924468994, -6.03439998626709, -5.160399913787842, -6.064700126647949, -6.067500114440918, -6.07889986038208, -6.064000129699707, -6.082099914550781, -6.082099914550781, -6.135300159454346, -5.958399772644043, -6.161499977111816, -6.175899982452393, -5.760499954223633, -5.662799835205078, -5.821499824523926, -5.684999942779541, -5.136300086975098, -5.081900119781494, -5.795300006866455, -5.756999969482422, -5.409900188446045, -5.321300029754639, -5.757199764251709, -5.713500022888184, -5.750899791717529, -5.736499786376953, -5.743800163269043, -5.788000106811523, -5.817200183868408, -5.653900146484375, -5.55709981918335, -5.420400142669678, -5.901000022888184, -5.92080020904541, -5.9527997970581055, -5.957799911499023, -5.9492998123168945, -5.973800182342529, -5.993000030517578, -5.9791998863220215, -5.979899883270264, -5.990699768066406, -4.564799785614014, -5.960299968719482, -5.652699947357178, -5.941100120544434, -5.914100170135498, -5.968999862670898, -6.332499980926514, -6.332499980926514, -6.332499980926514, -6.332499980926514, -6.332499980926514, -5.995500087738037, -5.97189998626709, -6.139599800109863, -6.3744001388549805, -6.380000114440918, -6.383999824523926, -5.484000205993652, -4.945799827575684, -5.161200046539307, -5.432199954986572, -5.4369001388549805, -5.35890007019043, -4.73829984664917, -5.507999897003174, -5.7444000244140625, -5.644700050354004, -5.674900054931641, -5.738100051879883, -5.482500076293945, -5.843900203704834, -5.804900169372559, -5.90939998626709, -5.801300048828125, -5.871399879455566, -5.91349983215332, -5.894800186157227, -5.93310022354126, -5.9390997886657715, -5.34630012512207, -5.8180999755859375, -5.844399929046631, -5.820199966430664, -5.838600158691406, -5.854400157928467, -5.923600196838379, -5.8850998878479, -5.828000068664551, -5.079599857330322, -5.281499862670898, -5.569699764251709, -5.806099891662598, -5.850500106811523, -6.282400131225586, -6.292799949645996, -5.884099960327148, -6.294899940490723, -6.296800136566162, -6.297299861907959, -6.277200222015381, -6.299499988555908, -6.301000118255615, -6.281199932098389, -6.280099868774414, -6.281000137329102, -6.2820000648498535, -6.306000232696533, -6.281599998474121, -6.307799816131592, -6.284800052642822, -4.842199802398682, -5.363399982452393, -5.803999900817871, -5.07919979095459, -5.48360013961792, -5.8404998779296875, -5.830599784851074, -5.855000019073486, -5.835999965667725, -5.517499923706055, -5.837100028991699, -5.8420000076293945, -5.869699954986572, -6.105599880218506, -5.904900074005127, -5.4243998527526855, -5.255300045013428, -5.748899936676025, -5.8520002365112305, -5.851799964904785, -5.8643999099731445, -5.829899787902832, -5.808300018310547, -6.196300029754639, -6.196300029754639, -6.196300029754639, -6.196400165557861, -6.196400165557861, -6.196400165557861, -6.196400165557861, -6.196400165557861, -6.196499824523926, -6.196499824523926, -6.196499824523926, -6.196499824523926, -6.196499824523926, -6.196499824523926, -6.196700096130371, -6.196800231933594, -5.697299957275391, -5.868100166320801, -6.218900203704834, -6.2195000648498535, -6.219600200653076, -6.220099925994873, -5.4882001876831055, -5.668499946594238, -5.656799793243408, -5.662700176239014, -5.329899787902832, -5.504899978637695, -5.7195000648498535, -5.630300045013428, -5.696100234985352, -5.823299884796143, -5.6315999031066895, -5.689499855041504, -5.870500087738037, -5.736000061035156, -6.11359977722168, -6.046000003814697, -6.114500045776367, -6.048699855804443, -6.0777997970581055, -6.1020002365112305, -6.01170015335083, -6.065199851989746, -6.070000171661377, -5.760700225830078, -5.722300052642822, -5.3470001220703125, -6.212399959564209, -6.212900161743164, -6.216700077056885, -6.21750020980835, -6.218400001525879, -6.2204999923706055, -6.225100040435791, -6.224800109863281, -6.226099967956543, -6.22629976272583, -6.227700233459473, -6.229599952697754, -6.229499816894531, -6.230899810791016, -6.231100082397461, -6.234000205993652, -6.233500003814697, -6.236499786376953, -6.237100124359131, -6.237500190734863, -6.245299816131592, -6.244500160217285, -6.249199867248535, -5.775000095367432, -6.257400035858154, -6.122700214385986, -6.094399929046631, -5.267099857330322, -6.115699768066406, -5.588500022888184, -5.339099884033203, -6.1356000900268555, -5.808700084686279, -5.650000095367432, -6.1178998947143555, -5.915200233459473, -6.044300079345703, -6.0208001136779785, -6.135799884796143, -5.720699787139893, -5.935200214385986, -6.074699878692627, -5.928199768066406, -5.966300010681152, -6.059199810028076, -6.141900062561035, -6.152299880981445, -6.118299961090088, -6.077300071716309, -6.159800052642822, -6.162700176239014, -5.0278000831604, -5.260799884796143, -5.270699977874756, -5.6020002365112305, -5.6057000160217285, -6.065700054168701, -6.066299915313721, -6.067399978637695, -6.067800045013428, -6.068299770355225, -6.076900005340576, -6.078499794006348, -6.0802001953125, -6.0802001953125, -6.084400177001953, -6.046500205993652, -5.9029998779296875, -6.030900001525879, -6.079100131988525, -6.09060001373291, -6.0472002029418945, -6.077400207519531, -6.674300193786621, -6.765600204467773, -6.7866997718811035, -6.654900074005127, -6.708799839019775, -6.7104997634887695, -6.814700126647949, -6.733099937438965, -6.733799934387207, -5.987500190734863, -5.950300216674805, -5.917399883270264, -5.943699836730957, -5.618199825286865, -6.405399799346924, -6.2266998291015625, -6.067999839782715, -6.270699977874756, -6.078199863433838], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.1353, 0.9886, 0.9582, 0.872, 0.8686, 0.868, 0.8627, 0.8537, 0.8268, 0.8262, 0.8215, 0.8139, 0.7901, 0.7868, 0.738, 0.7367, 0.7366, 0.7357, 0.7269, 0.7078, 0.6752, 0.6657, 0.6479, 0.6391, 0.6365, 0.6331, 0.6279, 0.6279, 0.6279, 0.6279, 0.6229, 0.6279, 0.6139, 0.6184, 0.4482, 0.5166, 0.3358, 0.2711, 0.1146, 0.4589, 0.3467, 0.0871, 0.2911, 0.1827, 0.2708, 0.2791, -0.2409, 0.4665, 0.3175, 0.3647, 1.0071, 1.0035, 0.9981, 0.934, 0.9201, 0.8959, 0.8359, 0.8338, 0.8287, 0.819, 0.8001, 0.7872, 0.7678, 0.7591, 0.7571, 0.7102, 0.7059, 0.6939, 0.6929, 0.6893, 0.6891, 0.689, 0.6855, 0.6839, 0.6781, 0.6736, 0.6709, 0.6697, 0.6662, 0.666, 0.5717, 0.6408, 0.6309, 0.401, 0.5728, 0.4164, 0.512, 0.5614, 0.2832, 0.4976, 0.3295, 0.1494, 0.3443, 0.3215, 0.3181, 0.0729, 1.1264, 1.0334, 1.0125, 0.9955, 0.9572, 0.9306, 0.9306, 0.9052, 0.8834, 0.8811, 0.8787, 0.8725, 0.8717, 0.8516, 0.851, 0.8478, 0.8443, 0.8233, 0.8139, 0.8087, 0.8073, 0.8002, 0.8002, 0.7782, 0.7765, 0.7547, 0.7504, 0.746, 0.7349, 0.7266, 0.7221, 0.7249, 0.701, 0.5277, 0.382, 0.652, 0.6266, 0.4172, 0.346, 0.5535, 0.4043, 0.3813, 0.2108, 0.2131, 0.2166, 0.2663, 1.2123, 1.1585, 1.1368, 1.0899, 1.0526, 1.0421, 1.0383, 1.0353, 1.0247, 1.0242, 1.0218, 1.0169, 1.0081, 0.9389, 0.9144, 0.8846, 0.8736, 0.8246, 0.8109, 0.8109, 0.8109, 0.8109, 0.8109, 0.8109, 0.8103, 0.7998, 0.797, 0.765, 0.7587, 0.7538, 0.753, 0.7048, 0.6659, 0.6709, 0.6282, 0.5951, 0.4226, 0.6097, 0.6306, 0.5498, 0.2981, 0.3747, -0.2666, 0.5481, 0.2981, 0.6401, -0.1373, 0.2108, 0.4565, 0.1247, 0.1866, 0.5178, 1.3066, 1.2301, 1.21, 1.1892, 1.1601, 1.1399, 1.1127, 1.1009, 1.072, 1.0402, 1.0076, 0.995, 0.9588, 0.941, 0.8976, 0.8891, 0.8876, 0.8873, 0.8857, 0.8853, 0.8836, 0.8834, 0.8822, 0.8799, 0.8795, 0.8789, 0.8783, 0.8781, 0.8775, 0.8765, 0.8745, 0.6217, 0.7017, 0.584, 0.1367, 0.2837, 0.4232, 0.2822, 0.2272, 0.1835, -0.3566, 0.136, 0.1053, -0.2025, 0.3516, -0.4012, 1.5469, 1.4042, 1.3288, 1.2135, 1.1871, 1.1708, 1.133, 1.1257, 1.0038, 1.0038, 1.0038, 1.0037, 1.0037, 1.0037, 1.0037, 1.0037, 1.0036, 1.0036, 1.0036, 1.0036, 1.0036, 1.0036, 1.0034, 1.0033, 0.9903, 0.9899, 0.9791, 0.9784, 0.9783, 0.9778, 0.9777, 0.9451, 0.908, 0.886, 0.6241, 0.7003, 0.6725, 0.4726, 0.4368, 0.5517, 0.2052, 0.2578, 0.5213, -0.2323, 0.7211, 0.3241, 0.6077, 0.0641, 0.2113, 0.3048, -0.5478, -0.0607, -0.406, 1.1686, 1.1054, 1.0366, 1.0292, 1.029, 1.0241, 1.022, 1.0201, 1.0194, 1.0143, 1.0136, 1.0119, 1.0117, 1.01, 1.0081, 1.0074, 1.0068, 1.0065, 1.0021, 1.0012, 1.0002, 0.9971, 0.9969, 0.992, 0.9878, 0.9831, 0.9759, 0.9752, 0.971, 0.9198, 0.7374, 0.9102, 0.3656, 0.1248, 0.8866, 0.3965, 0.1172, 0.758, 0.2026, 0.5021, 0.4361, 0.7456, -0.5048, 0.0843, 0.4558, -0.1011, -0.3023, 0.1353, 0.5341, 0.5864, 0.2518, -0.1204, 0.1982, -0.0805, 2.0982, 1.921, 1.6888, 1.6163, 1.4522, 1.2126, 1.2119, 1.2103, 1.2098, 1.209, 1.1971, 1.1949, 1.1925, 1.1924, 1.1866, 0.9998, 0.9809, 0.9807, 0.814, 0.7993, 0.7461, 0.6333, 0.4382, 0.4231, 0.4001, 0.3995, 0.3975, 0.3956, 0.3697, 0.369, 0.3682, 0.3086, 0.1826, 0.1021, -0.1166, -0.4023, 0.0445, -0.169, -0.4174, -0.151, -0.9173]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 6, 2, 3, 2, 3, 3, 5, 4, 5, 2, 1, 2, 3, 4, 5, 1, 2, 2, 3, 3, 1, 4, 2, 3, 4, 1, 3, 6, 3, 1, 2, 2, 4, 3, 1, 2, 6, 1, 1, 1, 1, 2, 3, 4, 6, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 5, 3, 5, 1, 3, 2, 3, 4, 6, 3, 1, 1, 2, 4, 5, 1, 2, 5, 1, 2, 3, 5, 2, 3, 1, 5, 4, 4, 1, 2, 3, 4, 5, 1, 1, 3, 5, 1, 1, 3, 3, 5, 3, 2, 3, 1, 4, 3, 2, 3, 1, 2, 3, 1, 3, 5, 2, 3, 2, 3, 1, 1, 3, 1, 2, 3, 3, 3, 2, 3, 4, 5, 6, 2, 3, 1, 2, 3, 4, 1, 2, 3, 3, 1, 2, 3, 3, 4, 1, 3, 1, 1, 4, 1, 2, 3, 4, 4, 4, 4, 4, 1, 1, 2, 3, 4, 1, 4, 1, 3, 3, 1, 3, 2, 1, 1, 2, 4, 2, 1, 4, 5, 4, 1, 2, 4, 5, 2, 5, 2, 4, 3, 2, 3, 1, 2, 3, 3, 2, 1, 2, 2, 1, 2, 3, 1, 6, 2, 1, 2, 3, 4, 5, 2, 3, 4, 1, 2, 3, 2, 1, 1, 4, 5, 6, 1, 2, 3, 3, 1, 4, 2, 3, 4, 2, 2, 2, 1, 2, 1, 2, 3, 4, 5, 2, 3, 3, 1, 2, 4, 1, 2, 4, 5, 6, 1, 3, 1, 4, 1, 2, 3, 4, 5, 1, 2, 2, 2, 3, 4, 5, 1, 2, 4, 6, 2, 4, 3, 3, 1, 2, 3, 1, 1, 2, 3, 3, 1, 2, 1, 2, 3, 2, 6, 2, 1, 2, 4, 1, 1, 2, 3, 5, 1, 2, 2, 1, 2, 1, 2, 1, 2, 2, 4, 5, 1, 1, 1, 2, 2, 6, 2, 5, 4, 1, 2, 3, 4, 2, 1, 2, 3, 4, 5, 1, 2, 3, 5, 6, 1, 3, 4, 5, 2, 1, 2, 1, 2, 2, 3, 1, 2, 3, 3, 2, 2, 3, 1, 3, 6, 1, 2, 3, 4, 1, 2, 3, 4, 1, 1, 2, 4, 3, 1, 2, 2, 3, 4, 6, 1, 2, 3], \"Freq\": [0.16217800678186073, 0.4865340203455822, 0.16217800678186073, 0.16217800678186073, 0.16217800678186073, 0.2567191495392073, 0.5134382990784147, 0.26050322813249244, 0.26050322813249244, 0.4835498964850693, 0.46959476806517725, 0.519482513489524, 0.5480265312458333, 0.5770520275562498, 0.2137246885840916, 0.2137246885840916, 0.2137246885840916, 0.2137246885840916, 0.2137246885840916, 0.3681252647843194, 0.3681252647843194, 0.3527034337636516, 0.4621167858001861, 0.5806591393526517, 0.4164593865210226, 0.4164593865210226, 0.4638326761824669, 0.23191633809123344, 0.23191633809123344, 0.4688174326135129, 0.23440871630675644, 0.23440871630675644, 0.4663769808275005, 0.6629690404546895, 0.22098968015156317, 0.4467098281719659, 0.45397535121846555, 0.47313994802288445, 0.3042267064596182, 0.3042267064596182, 0.3042267064596182, 0.41668871077911024, 0.42904552730182305, 0.42905621698741164, 0.18234527133858883, 0.18234527133858883, 0.18234527133858883, 0.18234527133858883, 0.18234527133858883, 0.39310834508590653, 0.39310834508590653, 0.18286931317284547, 0.18286931317284547, 0.18286931317284547, 0.18286931317284547, 0.30150903954058605, 0.30150903954058605, 0.30150903954058605, 0.30150903954058605, 0.544599634618475, 0.44490828404767807, 0.5381365742813071, 0.37536158387205376, 0.37536158387205376, 0.28256004459527667, 0.28256004459527667, 0.28256004459527667, 0.28256004459527667, 0.45840772097750676, 0.4332079935735968, 0.20728286864875164, 0.20728286864875164, 0.20728286864875164, 0.20728286864875164, 0.25493087266455444, 0.25493087266455444, 0.25493087266455444, 0.2814223864539497, 0.2814223864539497, 0.2814223864539497, 0.2814223864539497, 0.3107346118561138, 0.3107346118561138, 0.42129978098001536, 0.42129978098001536, 0.5163650687402876, 0.3905175876505148, 0.2614917065710271, 0.34865560876136953, 0.08716390219034238, 0.08716390219034238, 0.08716390219034238, 0.4428419756856829, 0.28678593618808434, 0.28678593618808434, 0.5238600132633336, 0.4289264357417563, 0.34014417222826193, 0.44512217459151604, 0.36677671792659583, 0.36677671792659583, 0.3886584804793793, 0.45554894591871686, 0.38787818101122484, 0.4405199968736192, 0.5142705919253371, 0.3297279277350773, 0.4399097130543429, 0.48089198155358415, 0.48868991212429697, 0.16289663737476565, 0.16289663737476565, 0.5730936724642922, 0.2865468362321461, 0.5183477655880595, 0.3089778718254921, 0.3089778718254921, 0.5435918714224751, 0.5610855018371342, 0.36670301852388926, 0.38057822769957533, 0.38057822769957533, 0.28248364006519483, 0.28248364006519483, 0.28248364006519483, 0.3838978535791325, 0.6774277889222002, 0.2485250527784789, 0.2485250527784789, 0.2485250527784789, 0.2485250527784789, 0.5043444688557579, 0.45563576638505, 0.5760601756040115, 0.1917896741491104, 0.1917896741491104, 0.1917896741491104, 0.45787704917634026, 0.20225658748336076, 0.4045131749667215, 0.20225658748336076, 0.5144699314890849, 0.1860734098203077, 0.1860734098203077, 0.5582202294609231, 0.3996541649715661, 0.3996541649715661, 0.3291253067775606, 0.3291253067775606, 0.4391149241035228, 0.3307555416750914, 0.3307555416750914, 0.13644172105158042, 0.27288344210316084, 0.40932516315474127, 0.13644172105158042, 0.517003437578252, 0.5053501651156695, 0.5182256636566087, 0.5173130946904703, 0.4292587385797003, 0.24199169133436463, 0.24199169133436463, 0.24199169133436463, 0.24199169133436463, 0.3267610939773355, 0.3267610939773355, 0.29862875376152725, 0.29862875376152725, 0.4505595216074868, 0.2637215940099306, 0.5274431880198612, 0.45547394323727974, 0.4532093252412479, 0.27780435044436286, 0.27780435044436286, 0.27780435044436286, 0.45030397161534785, 0.40753671369669825, 0.20376835684834912, 0.20376835684834912, 0.5279705710008407, 0.2152183116916316, 0.2152183116916316, 0.2152183116916316, 0.2152183116916316, 0.4631473079377929, 0.5117949052876251, 0.43117830791132894, 0.43117830791132894, 0.4436726149793364, 0.4653265916120113, 0.5263985647913142, 0.3886000421223134, 0.3886000421223134, 0.6234318948580658, 0.45989203382984895, 0.38214524929967186, 0.28023880512284943, 0.28023880512284943, 0.45446342949298396, 0.32454741907982865, 0.32454741907982865, 0.32454741907982865, 0.33050318276899315, 0.33050318276899315, 0.45285963826269937, 0.22339647376549598, 0.11169823688274799, 0.335094710648244, 0.11169823688274799, 0.22339647376549598, 0.2887783794104986, 0.2887783794104986, 0.2887783794104986, 0.2808712242621272, 0.2808712242621272, 0.5617424485242544, 0.661667486881383, 0.3358771155584981, 0.7218158116685438, 0.33582852874272756, 0.33582852874272756, 0.33582852874272756, 0.30162076520845227, 0.30162076520845227, 0.30162076520845227, 0.4501532789771055, 0.5528700862474296, 0.2764350431237148, 0.28971460411835853, 0.5794292082367171, 0.5110470572364295, 0.3851082138529178, 0.5326477258712902, 0.5306505631584114, 0.31451056529017385, 0.4717658479352608, 0.19469006199922495, 0.19469006199922495, 0.19469006199922495, 0.19469006199922495, 0.19469006199922495, 0.28019232602994454, 0.28019232602994454, 0.46491642468434385, 0.26926802720087756, 0.26926802720087756, 0.26926802720087756, 0.11622860756127615, 0.3486858226838285, 0.3486858226838285, 0.11622860756127615, 0.11622860756127615, 0.53852380886883, 0.4578996992925352, 0.3333072529426676, 0.3333072529426676, 0.3716996235346559, 0.18584981176732795, 0.18584981176732795, 0.18584981176732795, 0.18584981176732795, 0.5385239279098435, 0.5747989553558135, 0.5807924245982885, 0.21478601070775527, 0.21478601070775527, 0.21478601070775527, 0.5160676643089752, 0.3526490377303288, 0.3526490377303288, 0.3526490377303288, 0.3526490377303288, 0.4273973191786162, 0.4273973191786162, 0.4572590299711349, 0.6810991861979552, 0.4220757041622302, 0.4220757041622302, 0.4530621016750515, 0.4368752715113756, 0.2075659515026527, 0.2075659515026527, 0.2075659515026527, 0.34838369324691437, 0.5015361119944923, 0.25076805599724616, 0.23694419630937882, 0.23694419630937882, 0.23694419630937882, 0.6541628267318669, 0.21805427557728896, 0.46775471996002776, 0.20814087495566583, 0.41628174991133166, 0.20814087495566583, 0.38747819674480843, 0.13688171311676167, 0.41064513935028507, 0.27376342623352334, 0.13688171311676167, 0.40452309971617834, 0.40452309971617834, 0.5747345583178297, 0.579630937753716, 0.193210312584572, 0.2627483645909345, 0.525496729181869, 0.5216842410023345, 0.26084212050116723, 0.46760378656539753, 0.4130548839876717, 0.4130548839876717, 0.43892019999858917, 0.5250422213363181, 0.4984030340513751, 0.45435714256155585, 0.36924346469964714, 0.36924346469964714, 0.4102772924991715, 0.4102772924991715, 0.48712086024819345, 0.2116692056345286, 0.2116692056345286, 0.2116692056345286, 0.2116692056345286, 0.6897502695672897, 0.32998676460409065, 0.247490073453068, 0.08249669115102266, 0.16499338230204533, 0.08249669115102266, 0.18112030280272318, 0.36224060560544635, 0.18112030280272318, 0.18112030280272318, 0.18112030280272318, 0.15128264509766687, 0.6051305803906675, 0.15128264509766687, 0.15128264509766687, 0.6073109339222514, 0.27312311232384817, 0.27312311232384817, 0.27237287066013843, 0.5447457413202769, 0.2856466449666927, 0.2856466449666927, 0.4102751352883298, 0.2051375676441649, 0.2051375676441649, 0.4609517564482004, 0.5772191646604862, 0.45532544215446585, 0.47469346580251326, 0.3797363614871402, 0.3797363614871402, 0.3797363614871402, 0.21790861580100065, 0.21790861580100065, 0.21790861580100065, 0.21790861580100065, 0.5385233603967298, 0.16061137140974815, 0.3212227428194963, 0.16061137140974815, 0.4381680077646734, 0.39061697751024427, 0.4555731526241484, 0.518403616253285, 0.4513085224257269, 0.5385229521423069, 0.4656431376443604, 0.42326577167218865, 0.21163288583609433, 0.21163288583609433, 0.21163288583609433, 0.2993766625853762, 0.5987533251707524, 0.2993766625853762], \"Term\": [\"actividad\", \"actividad\", \"actividad\", \"actividad\", \"actividad\", \"actual\", \"actual\", \"afectar\", \"afectar\", \"aglomeraci\\u00f3n\", \"aislamiento\", \"alianza\", \"alimenticio\", \"alimento\", \"alto\", \"alto\", \"alto\", \"alto\", \"alto\", \"area\", \"area\", \"areas\", \"asociar\", \"aspecto\", \"atender\", \"atender\", \"aumentar\", \"aumentar\", \"aumentar\", \"avanzar\", \"avanzar\", \"avanzar\", \"ayudar\", \"bill\\u00f3n\", \"bill\\u00f3n\", \"calamidad\", \"california\", \"cano\", \"cantidad\", \"cantidad\", \"cantidad\", \"capacidad\", \"capacitaci\\u00f3n\", \"capacitar\", \"caso\", \"caso\", \"caso\", \"caso\", \"caso\", \"centro\", \"centro\", \"cerrar\", \"cerrar\", \"cerrar\", \"cerrar\", \"ciudad\", \"ciudad\", \"ciudad\", \"ciudad\", \"comerciante\", \"condonacion\", \"confiable\", \"confirmar\", \"confirmar\", \"considerar\", \"considerar\", \"considerar\", \"considerar\", \"consistir\", \"constante\", \"contagiar\", \"contagiar\", \"contagiar\", \"contagiar\", \"contagio\", \"contagio\", \"contagio\", \"contar\", \"contar\", \"contar\", \"contar\", \"contingencia\", \"contingencia\", \"controlar\", \"controlar\", \"corps\", \"covid\", \"covid-19\", \"covid-19\", \"covid-19\", \"covid-19\", \"covid-19\", \"creacion\", \"crear\", \"crear\", \"cubrebocas\", \"cuidar\", \"cuomo\", \"cuyo\", \"dato\", \"dato\", \"decretar\", \"desechable\", \"desocupacion\", \"deuda\", \"diagnosticar\", \"distinto\", \"e\", \"economia\", \"economica\", \"economica\", \"economica\", \"economico\", \"economico\", \"elemento\", \"empleador\", \"empleador\", \"emplear\", \"empresa\", \"enfermedad\", \"entidad\", \"entidad\", \"entregar\", \"entregar\", \"entregar\", \"especial\", \"esperar\", \"establecer\", \"establecer\", \"establecer\", \"establecer\", \"establecimiento\", \"esteriles\", \"estimulos\", \"evitar\", \"evitar\", \"evitar\", \"facilitar\", \"familia\", \"familia\", \"familia\", \"federal\", \"fiscal\", \"fiscal\", \"fiscal\", \"foco\", \"foco\", \"fondo\", \"fondo\", \"gasto\", \"gobernador\", \"gobernador\", \"gobernar\", \"gobernar\", \"gobernar\", \"gobernar\", \"gratis\", \"habilidad\", \"hara\", \"health\", \"herramienta\", \"hospital\", \"hospital\", \"hospital\", \"hospital\", \"hotel\", \"hotel\", \"impactar\", \"impactar\", \"importante\", \"impuesto\", \"impuesto\", \"indicaci\\u00f3n\", \"indicar\", \"infeccion\", \"infeccion\", \"infeccion\", \"infectar\", \"informacion\", \"informacion\", \"informacion\", \"informal\", \"ingresar\", \"ingresar\", \"ingresar\", \"ingresar\", \"instalar\", \"institucion\", \"interesar\", \"interesar\", \"jefe\", \"jornada\", \"lanzar\", \"limitar\", \"limitar\", \"liquidez\", \"luis\", \"madre\", \"manejar\", \"manejar\", \"mascarilla\", \"masivo\", \"masivo\", \"masivo\", \"medicar\", \"medicar\", \"medicosreducir\", \"medir\", \"medir\", \"medir\", \"medir\", \"medir\", \"mejorar\", \"mejorar\", \"mejorar\", \"meter\", \"meter\", \"meter\", \"movilidad\", \"municipio\", \"necesario\", \"necesidad\", \"necesidad\", \"necesidad\", \"negocio\", \"negocio\", \"negocio\", \"nominar\", \"numerar\", \"numerar\", \"obrar\", \"obrar\", \"ofrecer\", \"operador\", \"operar\", \"optar\", \"paciente\", \"paciente\", \"pandemia\", \"pandemia\", \"pandemia\", \"pandemia\", \"pandemia\", \"paquete\", \"paquete\", \"perder\", \"personal\", \"personal\", \"personal\", \"personar\", \"personar\", \"personar\", \"personar\", \"personar\", \"pertinente\", \"plantilla\", \"plataforma\", \"plataforma\", \"poblacion\", \"poblacion\", \"poblacion\", \"poblacion\", \"poblacion\", \"poblacional\", \"pobreza\", \"pobrezapoblacion\", \"poder\", \"poder\", \"poder\", \"policia\", \"poner\", \"poner\", \"poner\", \"poner\", \"positivo\", \"positivo\", \"potosi\", \"practicamente\", \"prevenir\", \"prevenir\", \"prioridad\", \"privar\", \"problema\", \"problema\", \"problema\", \"productivo\", \"profesional\", \"profesional\", \"programar\", \"programar\", \"programar\", \"propagacion\", \"propagacion\", \"proteccion\", \"proteger\", \"proteger\", \"proteger\", \"prueba\", \"publicar\", \"publicar\", \"publicar\", \"publicar\", \"publicos\", \"publicos\", \"quedar\", \"r\", \"r\", \"radioterapia\", \"radioterapia\", \"reduccion\", \"reduccion\", \"reducci\\u00f3n\", \"relevante\", \"relevante\", \"renegociacion\", \"representar\", \"residente\", \"respiratorio\", \"restaurante\", \"restaurante\", \"resultar\", \"resultar\", \"revision\", \"riesgo\", \"riesgo\", \"riesgo\", \"riesgo\", \"salario\", \"salud\", \"salud\", \"salud\", \"salud\", \"salud\", \"sanitario\", \"sanitario\", \"sanitario\", \"sanitario\", \"sanitario\", \"sector\", \"sector\", \"sector\", \"sector\", \"seguridad\", \"servicio\", \"servicio\", \"sintomas\", \"sintomas\", \"situacion\", \"situacion\", \"social\", \"social\", \"social\", \"solicitar\", \"sonororeducir\", \"sospechoso\", \"soto\", \"suspension\", \"suspension\", \"suspension\", \"tasar\", \"tasar\", \"tasar\", \"tasar\", \"totalidad\", \"trabajador\", \"trabajador\", \"trabajador\", \"transferencia\", \"transmision\", \"triaje\", \"united\", \"vacaci\\u00f3n\", \"validar\", \"vehiculos\", \"virus\", \"virus\", \"virus\", \"virus\", \"vulnerable\", \"vulnerable\", \"vulnerable\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [3, 2, 7, 5, 4, 6, 8, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el1544819293513184721773010802\", ldavis_el1544819293513184721773010802_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el1544819293513184721773010802\", ldavis_el1544819293513184721773010802_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el1544819293513184721773010802\", ldavis_el1544819293513184721773010802_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyLDAvis.gensim\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda, corpus, dictionary)\n",
    "pyLDAvis.save_html(vis, \"../../../data/lda/lda.html\")\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}